#!/bin/bash

#SBATCH --job-name=TEST # Job name

##SBATCH --mail-type=END,FAIL # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mail-user=milias@theor.jinr.ru # Where to send mail

#SBATCH --no-requeue
#SBATCH --ntasks=1 # Run on a single CPU
#SBATCH --cpus-per-task=8

##SBATCH --mem=1000mb # Job memory request
#SBATCH --mem=4GB # Job memory request

#SBATCH --time=1-00:00:00 # Time limit days-hrs:min:sec
#SBATCH --tmp=1G
#SBATCH --propagate=NONE
##SBATCH --array=1-5 # array of 5 jobs

#SBATCH --output=NONE

#SBATCH --partition=sl7 # allocate SL7 node only

#log=log_slurm_job.%j.%N.std_out_err
log=slurm_job.logfile_$SLURM_CLUSTER_NAME.$SLURM_JOB_PARTITION.N$SLURM_JOB_NODELIST.n$SLURM_NTASKS


echo -e "\nRunning on host `hostname`" >> $log
echo -e " Job start date: `date` "        >> $log

echo -e "\nJob user is SLURM_JOB_USER= $SLURM_JOB_USER"  >> $log
echo -e "User job SLURM_JOB_NAME=$SLURM_JOB_NAME has assigned ID SLURM_JOBID=$SLURM_JOBID" >> $log
echo -e "This job was submitted from the computer SLURM_SUBMIT_HOST=$SLURM_SUBMIT_HOST" >> $log
echo -e "and from the home directory SLURM_SUBMIT_DIR:" >> $log
echo -e "SLURM_SUBMIT_DIR = $SLURM_SUBMIT_DIR" >> $log

echo -e "Job is running on the cluster compute node: SLURM_CLUSTER_NAME=$SLURM_CLUSTER_NAME"  >> $log
echo -e "and is employing SLURM_JOB_NUM_NODES=$SLURM_JOB_NUM_NODES node/nodes:"  >> $log
echo -e "SLURM_JOB_NODELIST = $SLURM_JOB_NODELIST"   >> $log
echo -e "Job partition is SLURM_JOB_PARTITION=$SLURM_JOB_PARTITION \n"  >> $log
echo -e "Number of allocated CPUs on each single node, SLURM_CPUS_ON_NODE=$SLURM_CPUS_ON_NODE ."  >> $log
echo -e "Number of all reserved threads over ALL nodes, SLURM_NTASKS=$SLURM_NTASKS ."   >> $log
echo -e "Job has reserved memory per node, SLURM_MEM_PER_NODE=$SLURM_MEM_PER_NODE MB of memory"  >> $log

# CPU model, total numer of CPUs, number of allocated CPUs
echo -e "The node's CPU \c"; cat /proc/cpuinfo | grep 'model name' | uniq   >> $log
NPROCS=`cat /proc/cpuinfo | grep processor | wc -l`   >> $log
echo "BTW, this node has total $NPROCS CPUs available for an EXCLUSIVE job."  >> $log
echo "Based on reserved memory, this node got $SLURM_CPUS_ON_NODE CPUs allocated for SLURM calculations." >> $log
echo "This job wants SLURM_NTASKS=$SLURM_NTASKS threads . "  >> $log

# Generate Machinefile for mpi such that hosts are in the same
# order as if run via srun
MACHINEFILE="nodes.$SLURM_JOB_PARTITION.$SLURM_JOB_ID"
srun -l /bin/hostname | sort -n | awk '{print $2}' > $MACHINEFILE
echo -e "\ngenerated machinefile for MPI, $MACHINEFILE"; ls -lt $PWD/$MACHINEFILE; echo "containing:"; cat $MACHINEFILE >> $log


echo -e "\n\n The total memory at the running node (in GB)"  >> $log
free -t -g  >> $log


# modules
echo -e "\n\n Kicking on modules:"
source /cvmfs/bmn.jinr.ru/config/x86_64-alma9/cluster_config.sh >> $log
module avail >> $log

# own application ...

echo -e " Job end date: `date` "        >> $log

exit 
