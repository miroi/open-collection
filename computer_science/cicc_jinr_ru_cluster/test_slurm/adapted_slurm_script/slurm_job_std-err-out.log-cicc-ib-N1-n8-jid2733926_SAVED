=== Started SLURM job on the CICC cluster ===

Running on host wni020.jinr.ru
 Job start date: Thu Dec  4 05:21:28 PM MSK 2025 

Job user is SLURM_JOB_USER= milias
User job SLURM_JOB_NAME=TEST has assigned ID SLURM_JOBID=2733926
This job was submitted from the computer SLURM_SUBMIT_HOST=lxui10.jinr.ru
and from the home directory SLURM_SUBMIT_DIR:
SLURM_SUBMIT_DIR = /afs/jinr.ru/user/m/milias/git_projects/open-collection/computer_science/cicc_jinr_ru_cluster/test_slurm/adapted_slurm_script
Job is running on the cluster compute node: SLURM_CLUSTER_NAME=cicc
and is employing SLURM_JOB_NUM_NODES=1 node/nodes:
SLURM_JOB_NODELIST = wni020
Job partition is SLURM_JOB_PARTITION=ib 

Number of allocated CPUs on each single node, SLURM_CPUS_ON_NODE=8 .
Number of all reserved threads over ALL nodes, SLURM_NTASKS=1 .
Job has reserved memory per node, SLURM_MEM_PER_NODE=4096 MB of memory
model name	: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz
BTW, this node has total 28 CPUs available for an EXCLUSIVE job.
Based on reserved memory, this node got 8 CPUs allocated for SLURM calculations.
This job wants SLURM_NTASKS=1 threads . 
wni020.jinr.ru


 The total memory at the running node (in GB)
               total        used        free      shared  buff/cache   available
Mem:             125           2         119           0           3         122
Swap:             15           0          15
Total:           141           2         135


 Disk system on the computing node wni020.jinr.ru  :
total 60
drwxrwxrwt.  12 root root  4096 Dec  4 17:21 tmp
drwxr-xr-x    5 root root     0 Dec  4 17:14 cvmfs
drwxr-xr-x. 145 root root  8192 Dec  4 13:57 etc
drwxr-xr-x   50 root root  1440 Dec  4 09:46 run
drwxr-xr-x   22 root root  3640 Dec  3 17:56 dev
drwxr-xr-x    2 root root     0 Dec  3 10:15 net
drwxr-xr-x    2 root root     0 Dec  3 10:15 misc
dr-xr-xr-x  518 root root     0 Dec  3 10:15 proc
dr-xr-xr-x   13 root root     0 Dec  3 10:15 sys
drwxr-xr-x.  14 root root  4096 Dec  2 21:18 root
dr-xr-xr-x.   5 root root  4096 Dec  2 21:17 boot
drwxr-xr-x.  20 root root  4096 Oct 17 16:27 var
drwxr-xr-x.  21 root root   288 Oct 16 10:17 home
drwxr-xr-x.   6 root root    62 Oct 16 10:14 opt
drwxr-xr-x.  13 root root   156 Oct 16 10:09 usr
drwxr-xr-x.   4 root root    27 Oct 16 09:54 i
drwxrwxr-x    2 root root  4096 Apr  4  2025 eos
drwxr-xr-x.   6 root root    51 Mar 19  2025 scr
lrwxrwxrwx    1 root root     7 Nov 20  2024 bin -> usr/bin
lrwxrwxrwx    1 root root     7 Nov 20  2024 lib -> usr/lib
lrwxrwxrwx    1 root root     9 Nov 20  2024 lib64 -> usr/lib64
drwxr-xr-x.   2 root root     6 Nov 20  2024 media
drwxr-xr-x.   2 root root     6 Nov 20  2024 mnt
lrwxrwxrwx    1 root root     8 Nov 20  2024 sbin -> usr/sbin
drwxr-xr-x.   2 root root     6 Nov 20  2024 srv
drwxr-xr-x   40 root root  4096 May 29  2024 stp
drwxr-xr-x  387 root root 16384 Jan  1  1970 afs
drwxrwxrwx    1 root root  4096 Jan  1  1970 eosdvl
drwxrwxrwx    1 root root  4096 Jan  1  1970 eosmpd
Filesystem              Size  Used Avail Use% Mounted on
/dev/mapper/SRV9WN-tmp   10G  105M  9.9G   2% /tmp
Filesystem      Size  Used Avail Use% Mounted on
AFS             2.0T     0  2.0T   0% /afs
variable TMPDIR=/scr/u/cicc-2733926
ls -lt /scr/u ?
total 0
ls -lt /scr ?
total 0
drwxrwxrwt. 2 root  root   6 Dec  4 17:21 u
drwxr-xr-x  4 cvmfs cvmfs 38 Oct 17 18:23 cvmfs2
drwx------. 3 root  root  19 Oct 16 09:54 sys
drwxr-xr-x  3 root  root  19 Mar 19  2025 eos
df: /scr/u/cicc-2733926: No such file or directory
Filesystem              Size  Used Avail Use% Mounted on
/dev/mapper/SRV9WN-scr  1.3T   82G  1.2T   7% /scr


 Kicking on modules:
========================================================================
                  Dear users of the BM@N experiment

       The environment for working with the current versions
           of FairSoft and FairRoot on the cluster loaded

 FairSoft: /cvmfs/bmn.jinr.ru/fairsoft/jan24p2/x86_64-alma9
 FairRoot: /cvmfs/bmn.jinr.ru/fairroot/v18.8.1/x86_64-alma9

          Please, carefully read the corresponding manual
                  before working on the cluser

 NICA cluster (ncx): https://bmn.jinr.int/how-to-use-the-nica-cluster
 CICC complex (lxui): https://bmn.jinr.int/jinr-cicc-complex
 HybriLIT platform (hydra): https://bmn.jinr.int/hybrilit-govorun
========================================================================

module avail ?
------------------------ /usr/share/Modules/modulefiles ------------------------
dot  module-git  module-info  modules  null  use.own  


 Checking presence of software:
Python ?
/var/spool/slurmd/job2733926/slurm_script: line 92: Python: command not found
gfortran ?
GNU Fortran (GCC) 11.5.0 20240719 (Red Hat 11.5.0-11)
Copyright (C) 2021 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

mpirun ?
/var/spool/slurmd/job2733926/slurm_script: line 96: mpirun: command not found


 Application software QE=/scr/u/milias/software/quantum-espresso/q-e_develop
ls: cannot access '/scr/u/milias/software/quantum-espresso/q-e_develop/.': No such file or directory


 Job end date: Thu Dec  4 05:21:29 PM MSK 2025 
