
Running on host dgx03.hydra.local
Time is Wed Aug 20 14:57:25 MSK 2025 


Job user is SLURM_JOB_USER= milias
User job SLURM_JOB_NAME=CUDAFor has assigned ID SLURM_JOBID=13311382
This job was submitted from the computer SLURM_SUBMIT_HOST=space06.hydra.local
and from the home directory SLURM_SUBMIT_DIR:
/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran
Job is running on the cluster compute node: SLURM_CLUSTER_NAME=gvr
and is employing SLURM_JOB_NUM_NODES=1 node/nodes:
SLURM_JOB_NODELIST = dgx03
Job partition is SLURM_JOB_PARTITION=dgx 

Number of allocated CPUs on each single node, SLURM_CPUS_ON_NODE=4 .
Number of all reserved threads over ALL nodes, SLURM_NTASKS=4 .
Job has reserved memory per node, SLURM_MEM_PER_NODE=65536 MB of memory
The node's CPU model name	: Intel(R) Xeon(R) CPU E5-2698 v4 @ 2.20GHz
BTW, this node has total 80 CPUs available for an EXCLUSIVE job.
Based on reserved memory, this node got 4 CPUs allocated for SLURM calculations.
This job wants SLURM_NTASKS=4 threads . 

 adding git module from source /cvmfs/nica.jinr.ru/sw/os/login.sh :
Script called without parameters. Defaulting to latest version of modules. For certain version use:
login.sh legacy - for packages from before 23.09.23 release
login.sh latest - for packages starting from 23.09.23 release

 all modules, including /cvmfs/nica.jinr.ru/sw/os/login.sh
-------------- /cvmfs/nica.jinr.ru/sw/202309/MODULES/slc7_x86-64 ---------------
abseil-cpp/v20230802.2-1        libtiff/v4.6.0-1                zstd/v1.5.5-1  
abseil-cpp/v20240116.2-1        libtirpc/v1.3.4-1               zstd/v1.5.6-1  
ACTS/v33.1.0-1                  LibTorch/v2.6.0-1               
ACTS/v35.2.0-1                  libxml2/v2.12.5-1               
ACTS/v36.0.0-1                  libxml2/v2.13.0-1               
ACTS/v37.2.0-1                  lz4/v1.9.4-1                    
ACTS/v40.0.0-1                  lz4/v1.9.4-2                    
ACTS/v41.1.0-1                  lzma/v5.6.1-1                   
alibuild-recipe-tools/v0.3.1-1  lzma/v5.6.2-1                   
AliEn-CAs/v2023.04.23-1         mfddev/0-1                      
AliEn-Runtime/v2024.03-1        mpddev/v23.09.23-1              
AliEn-Runtime/v2024.03-2        mpddev/v23.12.23-1              
ApMon-CPP/v2.2.8-a6-1           mpddev/v24.03.24-1              
autotools/v1.7.0-1              mpddev/v24.06.24-1              
Boost/v1.83.0-1                 mpddev/v24.09.24-1              
Boost/v1.83.0-2                 mpddev/v24.12.24-1              
bzip2/v1.0.8-1                  mpddev/v25.03.25-1              
Catch2/v3.5.3-1                 mpddev/v25.06.03-1              
Catch2/v3.6.0-1                 mpdroot/v23.09.23-1             
clang-format/v18.1.1-1          mpdroot/v23.12.23-1             
clang-format/v18.1.8-1          mpdroot/v24.03.24-1             
CMake/v3.28.3-1                 mpdroot/v24.06.24-1             
CMake/v3.29.6-1                 mpdroot/v24.09.24-1             
CUDA/v11.8-1                    mpdroot/v24.12.24-1             
curl/v8.6.0-1                   mpdroot/v25.03.25-1             
curl/v8.8.0-1                   mpdroot/v25.06.03-1             
DD4hep/v1.27.2-1                mxpfit/vCPC-1                   
DD4hep/v1.29-1                  mxpfit/vCPC-2                   
DD4hep/v1.30.0-pre-1            ndmspc/v0.20240624.0-1          
DDS/v3.7.23-1                   NICA_scheduler/v22.08.0-1       
DDS/v3.10.0-1                   NICA_scheduler/v24.06.0-1       
EDM4hep/v0.10.5-1               nicadist-recipe-tools/v0.3.1-1  
EDM4hep/v0.10.5-2               ninja/v1.11.1-1                 
EDM4hep/v0.99.1-1               ninja/v1.12.1-1                 
Eigen3/v3.4.0-1                 nlohmann_json/v3.11.3-1         
Eigen3/v3.4.0-2                 nlohmann_json/v3.11.3-2         
EMACS/v29.2-1                   OpenSSH/v9.7.1-1                
emulzie/v1.0.0-1                OpenSSH/v9.7.1-2                
EnvironmentModules/v5.4.0-1     OpenSSL/v3.2.1-1                
FairCMakeModules/v1.0.0-1       OpenSSL/v3.3.1-1                
FairCMakeModules/v1.0.0-2       PCRE/v8.45-1                    
FairLogger/v1.11.1-1            PFSimple/v2024.03.28-gvr-1      
FairLogger/v2.0.0-1             PFSimple/v2024.03.28-hlit-1     
FairMQ/v1.8.4-1                 PFSimple/v2024.03.28-knl-1      
FairMQ/v1.8.4-2                 pigz/v2.8-1                     
FairRoot/v18.6.10-1             podio/v0.17.4-1                 
FairRoot/v18.6.10-2             podio/v0.17.4-2                 
FFTW/v3.3.10-1                  podio/v1.1.0-1                  
FFTW/v3.3.10-2                  PostgreSQL/v16.2-1              
FlatBuffers/v23.5.26-1          PostgreSQL/v16.3-1              
FlatBuffers/v24.3.25-1          protobuf/v24.4-1                
fmt/v10.1.1-1                   protobuf/v27.1-1                
fmt/v10.2.1-1                   pythia/v8.3.9-1                 
freeglut/v3.4.0-1               pythia/v8.3.12-1                
freeglut/v3.6.0-1               pythia6/v6.4.28-1               
FreeType/v2.13.2-1              pythia6/v6.4.28-2               
FreeType/v2.13.2-2              Pythia8JAM2/v8.2.44-1           
GCC-ToolChain/v13.2.0-1         Python-modules-list/v2024.03-1  
GEANT3/v4.3-1                   Python-modules-list/v2024.06-1  
GEANT3/v4.4-1                   Python-modules/v2024.03-1       
GEANT4/v11.1.3-1                Python-modules/v2024.06-1       
GEANT4/v11.2.1-1                Python/v3.11.8-1                
GEANT4_VMC/v6.4-1               Python/v3.12.4-1                
GEANT4_VMC/v6.6.2-1             QnTools/v2023.08.20-1           
generators/v2023.09-1           RapidYAML/v0.7.0-1              
generators/v2024.06-1           ROOT/v6.28.12-1                 
giflib/v5.2.2-1                 ROOT/v6.32.06-1                 
git/v2.44.0-1                   simulation/v2024.03-1           
git/v2.45.2-1                   simulation/v2024.06-1           
gl2ps/v1.4.1-1                  sqlite/v3.45.1-1                
glew/v2.3.0-pre-1               sqlite/v3.46.0-1                
GSL/v2.7-1                      TBB/v2021.10.0-1                
GSL/v2.8-1                      TBB/v2021.12.0-1                
HepMC/v2.6.11-1                 texinfo/v7.1.1-1                
HepMC/v2.6.11-2                 UUID/v2.39.3-1                  
HepMC3/v3.2.7-1                 UUID/v2.40.1-1                  
HepMC3/v3.3.0-1                 Vc/v1.4.4-gvr-1                 
HepPDT/v3.04.01-1               Vc/v1.4.4-hlit-1                
JAM2/v2.0097-1                  Vc/v1.4.4-knl-1                 
KFParticle/v2020.06.10-gvr-1    VGM/v5.2-1                      
KFParticle/v2020.06.10-hlit-1   VGM/v5.3-1                      
KFParticle/v2020.06.10-knl-1    VMC/v2.0-1                      
LCIO/v2.20.2-1                  VMC/v2.0-2                      
LCIO/v2.22.1-1                  xerces-c/v3.2.5-1               
LHAPDF/v6.5.2-1                 xerces-c/v3.2.5-2               
LHAPDF/v6.5.2-2                 XGBoost/v3.0.0-1                
libbsd/v0.12.2-1                XRootD/v5.6.9-1                 
libffi/v3.4.6-1                 XRootD/v5.6.9-2                 
libICU/v73.2-1                  xxHash/v0.8.2-1                 
libICU/v75.1-1                  xxHash/v0.8.2-2                 
libjpeg-turbo/v3.0.2-1          yaml-cpp/v0.8.0-1               
libjpeg-turbo/v3.0.3-1          yaml-cpp/v0.8.0-2               
libmd/v1.1.0-1                  ZeroMQ/v4.3.5-1                 
libpng/v1.6.43-1                ZeroMQ/v4.3.5-2                 
libpng/v1.6.43-2                zlib/v1.3.1-1                   

-------------- /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/modulefiles --------------
ABINIT/v9.10.3_openmpi411              Ginac/v1.7.3-1                      
ABINIT/v10.0.3_openmpi411              GMP/v6.2.1_gcc1120                  
ABINIT/v10.0.7_openmpi411              GROMACS/v5.1.3_gcc485_cuda80        
AmberTools/v22                         GROMACS/v2019.3                     
AMS/v2021.107_intel                    GROMACS/v2024.3                     
AMS/v2021.107_openmpi                  GSL/v1.16-1                         
BASE/1.0                               GSL/v2.6                            
CLN/v1.3.4-1                           GVR/v1.0-1 <L>                      
CMake/v3.29.2                          intel-qs/v20-07-14                  
COMSOL/v6.2                            intel-qs/v21-01-14                  
cuda/v8.0-1                            intel/oneapi                        
cuda/v9.2                              intel/v2018.1.163-9                 
cuda/v10.0-1                           intel/v2019.3.199                   
cuda/v10.1-1                           intel/v2021.1                       
cuda/v11.4                             JAM/v1.90596                        
cuda/v12.1                             java/v8u91-1                        
cuda/v12.4                             java/v8u181                         
DIRAC/v19.0_intel2018                  Julia/v1.11.5                       
dssp/v2.3.0                            LAMMPS/v02.04.25                    
ELPA/v2020.05.001_intel2018_python365  LAMMPS/v12.12.18                    
ELPA/v2025.01.002_oneapi               LAPACK/v3.9.0                       
EMACS/v25.3                            LAPACK/v3.12.0_gcc1230              
EOS/v1.0                               libpqxx/v7.0_gcc910                 
FairRoot/oct17p1                       MAGMA/v2.6.1_gcc830_cuda101         
FairRoot/v16.06_gcc485                 Maple/v2020.2                       
FairRoot/v18.0.4                       Mathematica/v11.2-1                 
FairRoot/v18.2.0_gcc485                MATLAB/R2022b                       
FairRoot/v18.2.1_gcc485                mpich/v4.1.2_gcc1120                
FairRoot/v18.4.2_gcc1120               ndm-lite/v1.0                       
FairSoft/apr21patches_gcc1120          opencv/v4.1.0                       
FairSoft/june19p1_gcc485               openmpi/v1.8.8-1                    
FairSoft/june19p2_gcc485               openmpi/v2.1.2-2                    
FairSoft/may16p1_gcc485                openmpi/v3.1.2                      
FairSoft/may18p1                       openmpi/v3.1.2_gcc1230              
FairSoft/oct17p1                       openmpi/v3.1.3                      
fftw/v3.3.7-2                          openmpi/v3.1.3_psm2                 
fftw/v3.3.7-5                          openmpi/v4.1.1_gcc1120              
fftw/v3.3.10_gcc1120                   openmpi/v4.1.6_gcc1230              
fftw/v3.3.10_openmpi503                openmpi/v5.0.3_gcc1230              
FLAIR/v2.3.0                           openmpi/v5.0.7_icc2021              
FLUKA/v2011.2x-8                       ORCA/v5.0.1                         
FLUKA/v2020.0.3                        ORCA/v6.0.0                         
FLUKA/v2021.2.2                        PandaRoot/dec17p2b                  
FLUKA/v2021.2.9                        PandaRoot/may19                     
FLUKA/v2023.3.2                        PostgreSQL/v12.1_gcc910             
FLUKA/v2023.3.3                        protobuf/v3.11.3                    
FLUKA/v2024.1                          pyorbit/v2023.11.20                 
FLUKA/v2025.1                          Python/v2.7.10-3                    
Gate/v9.3                              Python/v3.6.5                       
Gate/v9.3-qttest                       Python/v3.10.2                      
gcc/v4.9.3-1                           Python/v3.10.13                     
gcc/v5.3.0-1                           quantum-espresso/v6.4.1             
gcc/v6.2.0-2                           quantum-espresso/v6.6_oneapi        
gcc/v7.2.0-1                           quantum-espresso/v7.3.1_openmpi503  
gcc/v8.2.0-1                           R/v4.3.2                            
gcc/v8.3.0                             reduce-algebra/svn-4830             
gcc/v9.1.0-1                           ROOT/v6-18-00                       
gcc/v9.4.0                             ROOT/v6.24.06-qttest                
gcc/v10.2.0                            ROOT/v6.24.06_gcc1120               
gcc/v11.2.0                            SMASH_gcc485/v1.8                   
gcc/v12.3.0                            Tesseract/v5.0.0_gcc1120            
GEANT4/v4.10.07.p01_gcc910             TRNG/v4.24_gcc102                   
GEANT4/v11.1.3-qttest                  Valgrind/v3.16.1_gcc485             
GEANT4/v11.1.3_gcc1120                 ViennaCL/v1.7.1_gcc1120_cuda101     
GEANT4/v11.1.3_gcc1120-mt              zlib/v1.2.11-1                      

Key:
<module-tag>  <L>=loaded  
Loading Python/v3.10.13
  Loading requirement: BASE/1.0


 All loaded modules:
Currently Loaded Modulefiles:
 1) GVR/v1.0-1      3) Python/v3.10.13   5) cuda/v12.4  
 2) BASE/1.0 <aL>   4) CMake/v3.29.2    

Key:
<module-tag>  <aL>=auto-loaded  

Running on host dgx03.hydra.local
Time is Wed Aug 20 14:57:37 MSK 2025 


 The total memory at the node (in GB)
              total        used        free      shared  buff/cache   available
Mem:            503          15         487           0           0         486
Swap:            31           0          31
Total:          535          15         519



 ls  :
CUDA-Fortran-Book
hydra_gpu-build_ampere.01
hydra_gpu-build_dgx3.01
log_slurm_job.13311382.dgx03.std_out_err
make.logfile_Govorun-ampere_SAVED
make.logfile_Govorun-dgx3_SAVED
make.logfile_Govorun-dgx_SAVED
make.logfile_WSL2_SAVED
readme_buildup_Govorun.rst
readme_buildup_WSL2.rst


 My PATH=/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/comm_libs/mpi/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/CMake/v3.29.2/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/Python/v3.10.13/bin:/cvmfs/nica.jinr.ru/sw/202309/slc7_x86-64/EnvironmentModules/v5.4.0-1/bin:/cvmfs/nica.jinr.ru/sw/os/linux/bin/:/lustre/home/user/m/milias/work/software/ams/linux.openmpi/ams2021.107/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:.:/lustre/home/user/m/milias/.local/bin:/lustre/home/user/m/milias/bin


 My LD_LIBRARY_PATH=/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/lib64:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/Python/v3.10.13/lib64:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/Python/v3.10.13/lib 

 python -v :Python 3.10.13

 nvidia-smi ? /usr/bin/nvidia-smi
Wed Aug 20 14:57:38 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-16GB           Off |   00000000:06:00.0 Off |                    0 |
| N/A   32C    P0             42W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Tesla V100-SXM2-16GB           Off |   00000000:07:00.0 Off |                    0 |
| N/A   33C    P0             42W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  Tesla V100-SXM2-16GB           Off |   00000000:0A:00.0 Off |                    0 |
| N/A   33C    P0             44W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  Tesla V100-SXM2-16GB           Off |   00000000:0B:00.0 Off |                    0 |
| N/A   31C    P0             43W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   4  Tesla V100-SXM2-16GB           Off |   00000000:85:00.0 Off |                    0 |
| N/A   33C    P0             45W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   5  Tesla V100-SXM2-16GB           Off |   00000000:86:00.0 Off |                    0 |
| N/A   35C    P0             42W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   6  Tesla V100-SXM2-16GB           Off |   00000000:89:00.0 Off |                    0 |
| N/A   34C    P0             44W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   7  Tesla V100-SXM2-16GB           Off |   00000000:8A:00.0 Off |                    0 |
| N/A   32C    P0             43W /  300W |       1MiB /  16384MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+


 nvcc ? ; /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/bin/nvcc
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2024 NVIDIA Corporation
Built on Thu_Mar_28_02:18:24_PDT_2024
Cuda compilation tools, release 12.4, V12.4.131
Build cuda_12.4.r12.4/compiler.34097967_0

 nvfortran ? ; /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/bin/nvfortran

nvfortran 24.5-1 64-bit target on x86-64 Linux -tp broadwell 
NVIDIA Compilers and Tools
Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

 pgfortran ? ; /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/bin/pgfortran

pgfortran (aka nvfortran) 24.5-1 64-bit target on x86-64 Linux -tp broadwell 
PGI Compilers and Tools
Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

 ls  /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.1/Linux_x86_64/23.5/compilers:
bin
etc
extras
include
include_acc
include_man
include-stdexec
include-stdpar
lib
license
man
share
src

 ls  /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.1/Linux_x86_64/23.5/compilers/bin:
compute-sanitizer
cuda-gdb
cuda-memcheck
cuobjdump
localrc
localrc-lock
makelocalrc
ncu
ncu-ui
nsys
nsys-ui
nvaccelerror
nvaccelinfo
nvc
nvc++
nvcc
nvcpuid
nvcudainit
nvdecode
nvextract
nvfortran
nv-nsight-cu-cli
nvprepro
nvprof
nvsize
nvunzip
nvzip
pgaccelerror
pgaccelinfo
pgc++
pgcc
pgcpuid
pgcudainit
pgf77
pgf90
pgf95
pgfortran
pgprepro
pgsize
pgunzip
pgzip
rcfiles
tools

 ls  /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.1/Linux_x86_64/23.5/compilers/lib:
acc_init_link_acc.o
acc_init_link_cuda.o
acc_init_link_host.o
acc_init_link_mp.o
acc_init_link_multicore.o
cuda_init_register_end.o
f90alt.o
f90i8st.o
f90main.o
hugebss.ld
initacc.o
initmp.o
libacccuda10.a
libacccuda10.so
libacccuda.a
libacccudas10.a
libacccudas.a
libacccuda.so
libaccdevaux10.a
libaccdevaux10.so
libaccdevaux110.a
libaccdevaux110.so
libaccdevaux113.a
libaccdevaux113.so
libaccdevaux.a
libaccdevaux.so
libaccdevice.a
libaccdevices.a
libaccdevice.so
libacchost.a
libacchosts.a
libacchost.so
libaccnotify.so
libaccprof.so
libaccstub.so
libaccstub_static.a
libblas.a
libblas_ilp64.a
libblas_ilp64.so
libblas_ilp64.so.0
libblas_lp64.a
libblas_lp64.so
libblas_lp64.so.0
libblas.so
libblas.so.0
libc.ipl
libcublas.ipl
libcudadevice.a
libcudadevice.so
libcudafor_102.a
libcudafor_102.so
libcudafor_110.a
libcudafor_110.so
libcudafor_113.a
libcudafor_113.so
libcudafor_118.a
libcudafor_118.so
libcudafor_120.a
libcudafor_120.so
libcudafor2.a
libcudafor2.so
libcudafor.a
libcudafor.so
libcudaforwrapblas117.a
libcudaforwrapblas117.so
libcudaforwrapblas.a
libcudaforwrapblas.so
libcudaforwrapnccl.a
libcudaforwrapnccl.so
libcudaforwraprand.a
libcudaforwraprand.so
libcudaforwrapsparse10.a
libcudaforwrapsparse10.so
libcudaforwrapsparse11.a
libcudaforwrapsparse11.so
libcudaforwrapsparse12.a
libcudaforwrapsparse12.so
libcudaforwraptensor_113.a
libcudaforwraptensor_113.so
libcudaforwraptensor_118.a
libcudaforwraptensor_118.so
libcudaforwraptensor.a
libcudaforwraptensor.so
libcudanvhpc.a
libcudanvhpc.so
libfmpich.ipl
libgomp.so
libgomp.so.1
libhugetlbfs_nvhpc.a
libhugetlbfs_nvhpc.so
libhxrt_dev_101.a
libhxrt_dev_110.a
libhxrt_dev_113.a
libhxrt_dev.a
liblapack.a
liblapack_ilp64.a
liblapack_ilp64.so
liblapack_ilp64.so.0
liblapack_lp64.a
liblapack_lp64.so
liblapack_lp64.so.0
liblapack.so
liblapack.so.0
libmem.il
libm.ipl
libmpich.ipl
libnsnvc.a
libnvc.a
libnvc.ipl
libnvcpumath.a
libnvcpumath-avx2.so
libnvcpumath-avx512.so
libnvcpumath-avx.so
libnvcpumath.so
libnvc.so
libnvf.a
libnvf-avx2.a
libnvf-avx2.so
libnvf.ipl
libnvf.so
libnvgpumath.bc
libnvhpcatm.a
libnvhpcatm.so
libnvhpcman.a
libnvhpcmanaux.a
libnvhpcmanaux.so
libnvhpcman.so
libnvhpcwrapcufft.a
libnvhpcwrapcufftmp.a
libnvhpcwrapcufftmp.so
libnvhpcwrapcufft.so
libnvhpcwrapnvtx.a
libnvhpcwrapnvtx.so
libnvhpcwrapshmem.a
libnvlamath.a
libnvlamath.so
libnvomp.a
libnvomp_dev_101.a
libnvomp_dev_110.a
libnvomp_dev_113.a
libnvomp_dev.a
libnvomp_ompt.a
libnvomp_ompt.so
libnvomp.so
libnvompstub.so
libnvompstub_static.a
libomp.so
libpgc.a
libpgc.so
libpgm.a
libpgmath.a
libpgmath.so
libpgm.so
libpthread.ipl
libstdc++.ipl
nvcpumath-avx2.ld
nvcpumath-avx512.ld
nvcpumath-avx.ld
nvhpc.ld
nvhpcloc.ld
nvhpc.syms
nvvm34
nvvm70
preinit_allbnd.o
preinit_all.o
preinit_bind.o
subchk.o
trace_init.o


I am in the directory CFB=/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book
/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book
cd chapter1/deviceQuery; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/deviceQuery'
nvfortran -O2  -o deviceQuery.out deviceQuery.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/deviceQuery'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/deviceQuery'
./deviceQuery.out

One CUDA device found

Device Number: 0
  GetDeviceProperties for device 0: Passed
  Device Name: Tesla V100-SXM2-16GB
  Compute Capability: 7.0
  Number of Multiprocessors: 80
  Max Threads per Multiprocessor: 2048
  Global Memory (GB):    15.766

  Execution Configuration Limits
    Max Grid Dims: 2147483647 x 65535 x 65535
    Max Block Dims: 1024 x 1024 x 64
    Max Threads per Block: 1024

make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/deviceQuery'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/deviceQuery'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/deviceQuery'
cd chapter1/increment; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment'
nvfortran -O2  -o increment.out increment.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment'
./increment.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment'
cd chapter1/increment2; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment2'
nvfortran -O2  -o increment2.out increment2.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment2'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment2'
./increment2.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment2'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment2'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/increment2'
cd chapter1/multidim; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/multidim'
nvfortran -O2  -o multidim.out multidim.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/multidim'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/multidim'
./multidim.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/multidim'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/multidim'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter1/multidim'
cd chapter2/limitingFactor; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/limitingFactor'
nvfortran -O2  -o limitingFactor.out limitingFactor.cuf
nvfortran -O2  -cuda=fastmath -o limitingFactorFastMath.out limitingFactor.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/limitingFactor'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/limitingFactor'
./limitingFactor.out
 Test Passed
./limitingFactorFastMath.out
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/limitingFactor'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/limitingFactor'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/limitingFactor'
cd chapter2/peakBandwidth; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/peakBandwidth'
nvfortran -O2  -o peakBandwidth.out peakBandwidth.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/peakBandwidth'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/peakBandwidth'
./peakBandwidth.out
  GetDeviceProperties for device 0: Passed
 Device Number: 0
   Device name: Tesla V100-SXM2-16GB
   Memory Clock Rate (KHz): 877000
   Memory Bus Width (bits): 4096
   Peak Memory Bandwidth (GB/s): 898.05
 
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/peakBandwidth'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/peakBandwidth'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter2/peakBandwidth'
cd chapter3/async; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/async'
nvfortran -O2  -o async.out async.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/async'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/async'
./async.out
 Device: Tesla V100-SXM2-16GB

 Time for sequential transfer and execute (ms):     3.546912    
   max error:    1.1920929E-07
 Time for asynchronous V1 transfer and execute (ms):     2.041664    
   max error:    1.1920929E-07
 Time for asynchronous V2 transfer and execute (ms):     2.033696    
   max error:    1.1920929E-07
 Time for asynchronous V3 transfer and execute (ms):     2.037600    
   max error:    1.1920929E-07
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/async'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/async'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/async'
cd chapter3/constant; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/constant'
nvfortran -O2  -o constant.out constant.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/constant'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/constant'
./constant.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/constant'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/constant'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/constant'
cd chapter3/cufILP; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufILP'
nvfortran -O2  -o cufILP.out cufILP.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufILP'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufILP'
./cufILP.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufILP'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufILP'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufILP'
cd chapter3/cufKernel; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel'
nvfortran -O2  -o cufKernel.out cufKernel.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel'
./cufKernel.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel'
cd chapter3/cufKernel2D ; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel2D'
nvfortran -O2  -o cufKernel2D.out cufKernel2D.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel2D'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel2D'
./cufKernel2D.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel2D'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel2D'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufKernel2D'
cd chapter3/cufReduction ; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufReduction'
nvfortran -O2  -o cufReduction.out cufReduction.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufReduction'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufReduction'
./cufReduction.out
 Program Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufReduction'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufReduction'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/cufReduction'
cd chapter3/local; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/local'
nvfortran -O2  -cuda -gpu=ptxinfo -c local.cuf
ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function 'localmem_k3_' for 'sm_70'
ptxas info    : Function properties for localmem_k3_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 10 registers, 360 bytes cmem[0]
ptxas info    : Compiling entry function 'localmem_k2_' for 'sm_70'
ptxas info    : Function properties for localmem_k2_
    8 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 16 registers, 376 bytes cmem[0]
ptxas info    : Compiling entry function 'localmem_k1_' for 'sm_70'
ptxas info    : Function properties for localmem_k1_
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 10 registers, 360 bytes cmem[0]
Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/local'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/local'
make[1]: Nothing to be done for `run'.
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/local'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/local'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/local'
cd chapter3/offsetNstride; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/offsetNstride'
nvfortran -O2  -c precision_m.cuf
nvfortran -O2  -o offsetNstride.out precision_m.o offsetNstride.cuf
offsetNstride.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/offsetNstride'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/offsetNstride'
./offsetNstride.out

Device: Tesla V100-SXM2-16GB
Transfer size (MB): 4
Single Precision

 Offset, Bandwidth (GB/s):
            0    512.0000    
            1    512.0000    
            2    512.0000    
            3    512.0000    
            4    512.0000    
            5    546.1334    
            6    512.0000    
            7    512.0000    
            8    512.0000    
            9    512.0000    
           10    512.0000    
           11    513.0020    
           12    512.0000    
           13    546.1334    
           14    512.0000    
           15    512.0000    
           16    546.1334    
           17    512.0000    
           18    512.0000    
           19    481.8823    
           20    512.0000    
           21    512.0000    
           22    512.0000    
           23    512.0000    
           24    512.0000    
           25    512.0000    
           26    512.0000    
           27    512.0000    
           28    546.1334    
           29    512.0000    
           30    512.0000    
           31    512.0000    
           32    512.0000    
 
 Stride, Bandwidth (GB/s):
            1    512.0000    
            2    327.6800    
            3    234.0571    
            4    178.0870    
            5    143.7193    
            6    115.3803    
            7    94.16092    
            8    79.53398    
            9    70.01710    
           10    63.50388    
           11    60.23529    
           12    55.72789    
           13    52.17834    
           14    48.47337    
           15    46.81143    
           16    47.62791    
           17    45.01099    
           18    44.28108    
           19    41.16583    
           20    39.96098    
           21    44.04301    
           22    43.57447    
           23    42.44559    
           24    42.89005    
           25    42.89005    
           26    43.80749    
           27    40.55445    
           28    39.96098    
           29    41.37374    
           30    38.82464    
           31    40.96000    
           32    43.11579    
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/offsetNstride'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/offsetNstride'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/offsetNstride'
cd chapter3/parallelism; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/parallelism'
nvfortran -O2  -c precision_m.cuf
nvfortran -O2  -o parallelism.out precision_m.o parallelism.cuf
parallelism.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/parallelism'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/parallelism'
./parallelism.out

Device Name: Tesla V100-SXM2-16GB
Compute Capability: 7.0
Single Precision

Thread-level parallelism runs

  Multiple Blocks per Multiprocessor
       Threads/Block         Bandwidth (GB/s)
                  32               55.69
                  64              246.11
                 128              423.86
                 256              508.63
                 512              544.96
                1024              508.63

  Single Block per Multiprocessor
       Threads/Block         Bandwidth (GB/s)
                  32               67.70
                  64              124.12
                 128              215.58
                 256              341.33
                 512              481.88
                1024              546.13

Intruction-level parallelism runs

  ILP=4, Single Block per Multiprocessor
       Threads/Block         Bandwidth (GB/s)
 *** Test Passed ***
                  32              174.30
 *** Test Passed ***
                  64              341.33
 *** Test Passed ***
                 128              481.88
 *** Test Passed ***
                 256              585.14
 *** Test Passed ***
                 512              585.14
 *** Test Passed ***
                1024              546.13
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/parallelism'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/parallelism'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/parallelism'
cd chapter3/pinned; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/pinned'
nvfortran   -o pinned.out pinned.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/pinned'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/pinned'
./pinned.out
 
 Device: Tesla V100-SXM2-16GB
 Transfer size (MB):     16.00000    
 
 Pageable transfers
   Host to Device bandwidth (GB/s):     8.625144    
   Device to Host bandwidth (GB/s):     11.43685    
 
 Pinned transfers
   Host to Device bandwidth (GB/s):     10.87351    
   Device to Host bandwidth (GB/s):     12.37491    
 *** Pinned transfers passed ***
 
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/pinned'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/pinned'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/pinned'
cd chapter3/sharedExample; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/sharedExample'
nvfortran -O2  -o sharedExample.out sharedExample.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/sharedExample'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/sharedExample'
./sharedExample.out
 Static case max error:    0.000000    
 Test Passed
 Dynamic case 1 max error:    0.000000    
 Test Passed
 Dynamic case 2 max error:    0.000000    
 Test Passed
 Dynamic case 3 max error:    0.000000    
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/sharedExample'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/sharedExample'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/sharedExample'
cd chapter3/transpose; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/transpose'
nvfortran -O2  -o transpose.out transpose.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/transpose'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/transpose'
./transpose.out

Device Name: Tesla V100-SXM2-16GB
Compute Capability: 7.0
 
Matrix size: 1024 1024,  Block size: 32  8,  Tile size: 32 32
grid:  32  32   1,   tBlock:  32   8   1

                  Routine         Bandwidth (GB/s)
       shared memory copy *** Test Passed ***
              771.37
          naive transpose *** Test Passed ***
              169.47
      coalesced transpose *** Test Passed ***
              436.44
  conflict-free transpose *** Test Passed ***
              755.72
       diagonal transpose *** Test Passed ***
              723.67
 
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/transpose'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/transpose'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter3/transpose'
cd chapter4/P2P/minimal; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/minimal'
nvfortran -O2  -o minimal.out minimal.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/minimal'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/minimal'
./minimal.out
FORTRAN STOP
 This program requires at least two GPUs
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/minimal'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/minimal'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/minimal'
cd chapter4/P2P/p2pAccess; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pAccess'
nvfortran -O2  -o p2pAccess.out p2pAccess.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pAccess'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pAccess'
./p2pAccess.out
Number of CUDA-capable devices: 1

Device 0: Tesla V100-SXM2-16GB
 
     0
  0  -   
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pAccess'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pAccess'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pAccess'
cd chapter4/P2P/directTransfer; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/directTransfer'
nvfortran -O2  -o directTransfer.out directTransfer.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/directTransfer'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/directTransfer'
./directTransfer.out
FORTRAN STOP
 Need at least two CUDA capable devices
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/directTransfer'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/directTransfer'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/directTransfer'
cd chapter4/P2P/p2pBandwidth; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pBandwidth'
nvfortran -O2  -o p2pBandwidth.out p2pBandwidth.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pBandwidth'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pBandwidth'
./p2pBandwidth.out
Number of CUDA-capable devices: 1

Device 0: Tesla V100-SXM2-16GB
 
Bandwidth (GB/s) for transfer size (MB):    16.000

 S\R   0
  0    -   
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pBandwidth'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pBandwidth'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/p2pBandwidth'
cd chapter4/P2P/transposeP2P; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/transposeP2P'
nvfortran  -c timing.f90
cc  -c wallclock.c
nvfortran -O2  -o transposeP2P.out timing.o wallclock.o transposeP2P.cuf
transposeP2P.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/transposeP2P'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/transposeP2P'
./transposeP2P.out
Number of CUDA-capable devices: 1

  Device 0: Tesla V100-SXM2-16GB
 

Array size: 1920x1920

CUDA block size: 32x8,  CUDA tile size: 32x32
dimGrid: 60x60x1,   dimBlock: 32x8x1

nDevices: 1, Local input array size: 1920x1920
p2pTileDim: 1920x1920

async mode:  T


 *** Test Passed ***

Bandwidth (GB/s):  195.10

make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/transposeP2P'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/transposeP2P'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/P2P/transposeP2P'
cd chapter4/MPI/mpiDevices; make build; make NPROCS=4 run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/mpiDevices'
mpif90 -O2  -o mpiDevices.out mpiDevices.cuf
/usr/bin/ld: warning: libatomic.so.1, needed by /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/comm_libs/12.4/hpcx/hpcx-2.19/ompi/lib/libmpi_usempif08.so, not found (try using -rpath or -rpath-link)
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/mpiDevices'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/mpiDevices'
mpiexec -np 4 ./mpiDevices.out
--------------------------------------------------------------------------
A request was made to bind to that would result in binding more
processes than cpus on a resource:

   Bind to:     CORE
   Node:        dgx03
   #processes:  2
   #cpus:       1

You can override this protection by adding the "overload-allowed"
option to your binding directive.
--------------------------------------------------------------------------
make[1]: *** [run] Error 1
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/mpiDevices'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/mpiDevices'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/mpiDevices'
cd chapter4/MPI/assignDevice; make build; make NPROCS=4 run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/assignDevice'
mpif90 -O2  -c ../common/mpiDeviceUtil.cuf
mpif90 -O2  -o assignDevice.out mpiDeviceUtil.o assignDevice.cuf
assignDevice.cuf:
/usr/bin/ld: warning: libatomic.so.1, needed by /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/comm_libs/12.4/hpcx/hpcx-2.19/ompi/lib/libmpi_usempif08.so, not found (try using -rpath or -rpath-link)
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/assignDevice'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/assignDevice'
mpiexec -np 4 ./assignDevice.out
--------------------------------------------------------------------------
A request was made to bind to that would result in binding more
processes than cpus on a resource:

   Bind to:     CORE
   Node:        dgx03
   #processes:  2
   #cpus:       1

You can override this protection by adding the "overload-allowed"
option to your binding directive.
--------------------------------------------------------------------------
make[1]: *** [run] Error 1
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/assignDevice'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/assignDevice'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/assignDevice'
cd chapter4/MPI/transposeMPI; make build; make NPROCS=4 run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/transposeMPI'
mpif90 -O2  -c ../common/mpiDeviceUtil.cuf
mpif90 -O2  -o transposeMPI.out mpiDeviceUtil.o transposeMPI.cuf
transposeMPI.cuf:
/usr/bin/ld: warning: libatomic.so.1, needed by /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/comm_libs/12.4/hpcx/hpcx-2.19/ompi/lib/libmpi_usempif08.so, not found (try using -rpath or -rpath-link)
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/transposeMPI'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/transposeMPI'
mpiexec -np 4 ./transposeMPI.out
--------------------------------------------------------------------------
A request was made to bind to that would result in binding more
processes than cpus on a resource:

   Bind to:     CORE
   Node:        dgx03
   #processes:  2
   #cpus:       1

You can override this protection by adding the "overload-allowed"
option to your binding directive.
--------------------------------------------------------------------------
make[1]: *** [run] Error 1
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/transposeMPI'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/transposeMPI'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter4/MPI/transposeMPI'
cd chapter5/rng_gpu; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/rng_gpu'
nvfortran -O2 -cudalib=curand  -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand  -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand  -o rng_gpu_sp.out precision_m.o curand_m.o  generate_randomnumbers.cuf
generate_randomnumbers.cuf:
nvfortran -O2 -cudalib=curand  -DDOUBLE -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand  -DDOUBLE -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand  -DDOUBLE -o rng_gpu_dp.out precision_m.o curand_m.o  generate_randomnumbers.cuf
generate_randomnumbers.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/rng_gpu'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/rng_gpu'
./rng_gpu_sp.out
Generating random numbers in single precision
   0.1454676       0.8201809       0.5503992       0.2948303    
 Test Passed
./rng_gpu_dp.out
Generating random numbers in double precision
   0.4348988043884129        0.9264169202024377        0.8118452111300192      
   0.3085554246353980     
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/rng_gpu'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/rng_gpu'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/rng_gpu'
cd chapter5/pi; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/pi'
nvfortran -O2 -cudalib=curand  -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand  -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand  -o pi_sp.out precision_m.o curand_m.o  compute_pi.cuf
compute_pi.cuf:
nvfortran -O2 -cudalib=curand  -DDOUBLE -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand  -DDOUBLE -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand  -DDOUBLE -o pi_dp.out precision_m.o curand_m.o  compute_pi.cuf
compute_pi.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/pi'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/pi'
./pi_sp.out
Compute pi in single precision
 Test Passed
  Samples=    100000  Pi=3.13632011  Error= 0.5273E-02
./pi_dp.out
Compute pi in double precision
 Test Passed
  Samples=    100000  Pi=3.13716000  Error= 0.4433E-02
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/pi'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/pi'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/pi'
cd chapter5/compute_pi_performance; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/compute_pi_performance'
nvfortran -O2 -cudalib=curand -DLOOP  -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand -DLOOP  -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand -DLOOP  -c sum_lock.cuf
nvfortran -O2 -cudalib=curand -DLOOP  -c sum_gpu.cuf
nvfortran -O2 -cudalib=curand -DLOOP  -o compute_pi_performance_sp.out precision_m.o curand_m.o sum_gpu.o sum_lock.o  compute_pi_performance.CUF
compute_pi_performance.CUF:
nvfortran -O2 -cudalib=curand -DLOOP  -DDOUBLE -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand -DLOOP  -DDOUBLE -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand -DLOOP  -DDOUBLE -c sum_lock.cuf
nvfortran -O2 -cudalib=curand -DLOOP  -DDOUBLE -c sum_gpu.cuf
nvfortran -O2 -cudalib=curand -DLOOP  -DDOUBLE -o compute_pi_performance_dp.out precision_m.o curand_m.o sum_gpu.o sum_lock.o  compute_pi_performance.CUF
compute_pi_performance.CUF:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/compute_pi_performance'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/compute_pi_performance'
./compute_pi_performance_sp.out
  Compute pi  in single precision (seed=                   1234567 )
  Times (CUF),(Two stages), (Single stage) (CPU):
   3.3960000E-03   5.9000002E-05   1.3480000E-03   8.0000000E-06
  Samples=     10000  Pi=3.16720009  Error= 0.2561E-01
  
 Test Passed
  Times (CUF),(Two stages), (Single stage) (CPU):
   2.4000001E-05   2.4000001E-05   5.7000001E-05   6.8000001E-05
  Samples=    100000  Pi=3.13919997  Error= 0.2393E-02
  
 Test Passed
  Times (CUF),(Two stages), (Single stage) (CPU):
   3.6000001E-05   3.2000000E-05   7.1000002E-05   6.1699998E-04
  Samples=   1000000  Pi=3.14109206  Error= 0.5007E-03
  
 Test Passed
./compute_pi_performance_dp.out
  Compute pi  in double precision (seed=                   1234567 )
  Times (CUF),(Two stages), (Single stage) (CPU):
   3.3710001E-03   5.6000001E-05   1.4220000E-03   1.6000000E-05
  Samples=     10000  Pi=3.12880000  Error= 0.1279E-01
  
 Test Passed
  Times (CUF),(Two stages), (Single stage) (CPU):
   2.6000000E-05   2.6000000E-05   6.1999999E-05   1.1900000E-04
  Samples=    100000  Pi=3.14676000  Error= 0.5167E-02
  
 Test Passed
  Times (CUF),(Two stages), (Single stage) (CPU):
   4.8999998E-05   4.0999999E-05   7.5000004E-05   1.2600000E-03
  Samples=   1000000  Pi=3.14274000  Error= 0.1147E-02
  
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/compute_pi_performance'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/compute_pi_performance'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/compute_pi_performance'
cd chapter5/mc_european; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/mc_european'
nvfortran -O2 -cudalib=curand  -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand  -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand  -o mc_european_sp.out precision_m.o curand_m.o  montecarlo_european_option.cuf
montecarlo_european_option.cuf:
nvfortran -O2 -cudalib=curand  -DDOUBLE -c ../common/precision_m.F90
nvfortran -O2 -cudalib=curand  -DDOUBLE -c ../common/curand_m.cuf
nvfortran -O2 -cudalib=curand  -DDOUBLE -o mc_european_dp.out precision_m.o curand_m.o  montecarlo_european_option.cuf
montecarlo_european_option.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/mc_european'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/mc_european'
./mc_european_sp.out
  European option with random numbers
  in single precisionm using                   1000000  samples
 Montecarlo  value of put option  =   0.1276108    
 BlackScholes value of put option =   0.1280212    
 Confidence interval of put option  = [   0.1269990     ,   0.1282226     ]
 Montecarlo value of call option  =    1.322458    
 BlackScholes value of call option=    1.323104    
 Confidence interval of call option  = [    1.319745     ,    1.325171     ]
 Elapsed time (ms) :    153.9499    
 Test Passed
./mc_european_dp.out
  European option with random numbers
  in double precision using                   1000000  samples
 Montecarlo  value of put option  =   0.1280019167019663     
 BlackScholes value of put option =   0.1280215707263190     
 Confidence interval of put option  = [   0.1273886989425720      , 
   0.1286151344613607      ]
 Montecarlo value of call option  =    1.322242692975767     
 BlackScholes value of call option=    1.323103872723463     
 Confidence interval of call option  = [    1.319531953505467      , 
    1.324953432446068      ]
 Elapsed time (ms) :    16.75638    
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/mc_european'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/mc_european'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter5/mc_european'
cd chapter6/finiteDifference; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifference'
nvfortran -O2  -c ../common/precision_m.cuf
nvfortran -O2  -c derivative_m.cuf
nvfortran -O2  -o finiteDifference.out derivative_m.o precision_m.o finiteDifference.cuf
finiteDifference.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifference'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifference'
./finiteDifference.out

Device Name: Tesla V100-SXM2-16GB
Compute Capability: 7.0
Single Precision

x derivatives

  Using shared memory tile of x-y: 64x4
   RMS error:    7.2519310E-06
   MAX error:    2.7179718E-05
   Average time (ms):    4.4032000E-03
   Average Bandwidth (GB/s):     476.2791    
   Test Passed

  Single syncthreads, using shared memory tile of x-y: 64x4
   RMS error:    7.2519310E-06
   MAX error:    2.7179718E-05
   Average time (ms):    4.2495998E-03
   Average Bandwidth (GB/s):     493.4940    
   Test Passed

  Using shared memory tile of x-y: 64x32
   RMS error:    7.2519310E-06
   MAX error:    2.7179718E-05
   Average time (ms):    4.8640002E-03
   Average Bandwidth (GB/s):     431.1579    
   Test Passed

y derivatives

  Using shared memory tile of x-y: 4x64
   RMS error:    7.2517619E-06
   MAX error:    2.7179718E-05
   Average time (ms):    6.1951997E-03
   Average Bandwidth (GB/s):     338.5124    
   Test Passed

  Using shared memory tile of x-y: 32x64
   RMS error:    7.2517619E-06
   MAX error:    2.7179718E-05
   Average time (ms):    4.4032000E-03
   Average Bandwidth (GB/s):     476.2791    
   Test Passed

z derivatives

  Using shared memory tile of x-z: 4x64
   RMS error:    7.2517541E-06
   MAX error:    2.7179718E-05
   Average time (ms):    6.1951997E-03
   Average Bandwidth (GB/s):     338.5124    
   Test Passed

  Using shared memory tile of x-z: 32x64
   RMS error:    7.2517541E-06
   MAX error:    2.7179718E-05
   Average time (ms):    4.3520001E-03
   Average Bandwidth (GB/s):     481.8824    
   Test Passed
 
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifference'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifference'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifference'
cd chapter6/limitingFactor; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/limitingFactor'
nvfortran -O2  -c ../common/precision_m.cuf
nvfortran -O2  -o limitingFactor.out precision_m.o limitingFactor.cuf
limitingFactor.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/limitingFactor'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/limitingFactor'
./limitingFactor.out

Device Name: Tesla V100-SXM2-16GB
Compute Capability: 7.0
Single Precision

x derivative with x-y tile: 64x4
   RMS error:    7.2519310E-06
   MAX error:    2.7179718E-05
   Average time (ms):    4.3520001E-03
   Mem Bandwidth (GB/s):     481.8824    
   Test Passed

x derivative mem with x-y tile: 64x4
   RMS error:     4.465209    
   MAX error:     6.361378    
   Average time (ms):    4.0960000E-03
   Mem Bandwidth (GB/s):     512.0000    

x derivative gmem with x-y tile: 64x4
   RMS error:     4.465209    
   MAX error:     6.361378    
   Average time (ms):    3.9423998E-03
   Mem Bandwidth (GB/s):     531.9481    

x derivative math with x-y tile: 64x4
   RMS error:     4.465209    
   MAX error:     6.361378    
   Average time (ms):    3.8400001E-03
   Mem Bandwidth (GB/s):     546.1333    
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/limitingFactor'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/limitingFactor'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/limitingFactor'
cd chapter6/finiteDifferenceStr; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifferenceStr'
nvfortran -O2  -c ../common/precision_m.cuf
nvfortran -O2  -c derivativeStr_m.cuf
nvfortran -O2  -o finiteDifferenceStr.out derivativeStr_m.o precision_m.o finiteDifferenceStr.cuf
finiteDifferenceStr.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifferenceStr'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifferenceStr'
./finiteDifferenceStr.out

Device Name: Tesla V100-SXM2-16GB
Compute Capability: 7.0
Single Precision

x derivatives

  Using shared memory tile of x-y: 64x4
   RMS error:    3.8798994E-06
   MAX error:    2.2888184E-05
   Average time (ms):    2.4166401E-02
   Average Bandwidth (GB/s):     86.77966    
   Test Passed

  Single syncthreads, using shared memory tile of x-y: 64x4
   RMS error:    3.8798994E-06
   MAX error:    2.2888184E-05
   Average time (ms):    2.3910400E-02
   Average Bandwidth (GB/s):     87.70878    
   Test Passed

  Using shared memory tile of x-y: 64x32
   RMS error:    3.8798994E-06
   MAX error:    2.2888184E-05
   Average time (ms):    7.3728003E-03
   Average Bandwidth (GB/s):     284.4444    
   Test Passed

y derivatives

  Using shared memory tile of x-y: 4x64
   RMS error:    3.8799290E-06
   MAX error:    2.2888184E-05
   Average time (ms):    8.2943998E-03
   Average Bandwidth (GB/s):     252.8395    
   Test Passed

  Using shared memory tile of x-y: 32x64
   RMS error:    3.8799290E-06
   MAX error:    2.2888184E-05
   Average time (ms):    4.5055998E-03
   Average Bandwidth (GB/s):     465.4546    
   Test Passed

z derivatives

  Using shared memory tile of x-z: 4x64
   RMS error:    3.8799230E-06
   MAX error:    2.2888184E-05
   Average time (ms):    8.2943998E-03
   Average Bandwidth (GB/s):     252.8395    
   Test Passed

  Using shared memory tile of x-z: 32x64
   RMS error:    3.8799230E-06
   MAX error:    2.2888184E-05
   Average time (ms):    4.4543999E-03
   Average Bandwidth (GB/s):     470.8046    
   Test Passed
 
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifferenceStr'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifferenceStr'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter6/finiteDifferenceStr'
cd chapter7/fft_test_c2c; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_c2c'
nvfortran -O2 -cudalib=cufft  -c ../common/precision_m.F90
nvfortran -O2 -cudalib=cufft  -c ../common/cufft_m.cuf
nvfortran -O2 -cudalib=cufft  -o fft_test_c2c_sp.out precision_m.o cufft_m.o fft_test_c2c.cuf 
fft_test_c2c.cuf:
nvfortran -O2 -cudalib=cufft  -DDOUBLE -c ../common/precision_m.F90
nvfortran -O2 -cudalib=cufft  -DDOUBLE -c ../common/cufft_m.cuf
nvfortran -O2 -cudalib=cufft  -DDOUBLE -o fft_test_c2c_dp.out precision_m.o cufft_m.o fft_test_c2c.cuf 
fft_test_c2c.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_c2c'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_c2c'
./fft_test_c2c_sp.out
  Transform from complex array
 1   1.0000  0.0000   0 -0.0000  0.0000
 2   1.6310  0.0000   1  0.0000 -0.0000
 3   0.7071  0.0000   2  0.5000  0.0000
 4  -1.0898  0.0000   3  0.0000 -0.5000
 5  -2.0000  0.0000   4  0.0000  0.0000
 6  -1.0898  0.0000   5 -0.0000  0.0000
 7   0.7071  0.0000   6  0.0000  0.0000
 8   1.6310  0.0000   7  0.0000 -0.0000
 9   1.0000  0.0000  -8 -0.0000  0.0000
10  -0.2168  0.0000  -7  0.0000 -0.0000
11  -0.7071  0.0000  -6  0.0000  0.0000
12  -0.3244  0.0000  -5 -0.0000 -0.0000
13   0.0000  0.0000  -4  0.0000 -0.0000
14  -0.3244  0.0000  -3  0.0000  0.5000
15  -0.7071  0.0000  -2  0.5000 -0.0000
16  -0.2168  0.0000  -1  0.0000  0.0000
 Test Passed
./fft_test_c2c_dp.out
  Transform from complex array
 1   1.0000  0.0000   0 -0.0000  0.0000
 2   1.6310  0.0000   1 -0.0000  0.0000
 3   0.7071  0.0000   2  0.5000 -0.0000
 4  -1.0898  0.0000   3 -0.0000 -0.5000
 5  -2.0000  0.0000   4  0.0000 -0.0000
 6  -1.0898  0.0000   5  0.0000 -0.0000
 7   0.7071  0.0000   6  0.0000 -0.0000
 8   1.6310  0.0000   7  0.0000  0.0000
 9   1.0000  0.0000  -8 -0.0000  0.0000
10  -0.2168  0.0000  -7  0.0000 -0.0000
11  -0.7071  0.0000  -6  0.0000  0.0000
12  -0.3244  0.0000  -5  0.0000  0.0000
13  -0.0000  0.0000  -4  0.0000  0.0000
14  -0.3244  0.0000  -3 -0.0000  0.5000
15  -0.7071  0.0000  -2  0.5000  0.0000
16  -0.2168  0.0000  -1 -0.0000 -0.0000
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_c2c'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_c2c'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_c2c'
cd chapter7/fft_test_r2c; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_r2c'
nvfortran -O2 -cudalib=cufft  -c ../common/precision_m.F90
nvfortran -O2 -cudalib=cufft  -c ../common/cufft_m.cuf
nvfortran -O2 -cudalib=cufft  -o fft_test_r2c_sp.out precision_m.o cufft_m.o fft_test_r2c.cuf 
fft_test_r2c.cuf:
nvfortran -O2 -cudalib=cufft  -DDOUBLE -c ../common/precision_m.F90
nvfortran -O2 -cudalib=cufft  -DDOUBLE -c ../common/cufft_m.cuf
nvfortran -O2 -cudalib=cufft  -DDOUBLE -o fft_test_r2c_dp.out precision_m.o cufft_m.o fft_test_r2c.cuf 
fft_test_r2c.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_r2c'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_r2c'
./fft_test_r2c_sp.out
  Transform from real array
 1  0 -0.0000  0.0000
 2  1  0.0000 -0.0000
 3  2  0.5000  0.0000
 4  3  0.0000 -0.5000
 5  4  0.0000  0.0000
 6  5 -0.0000  0.0000
 7  6  0.0000  0.0000
 8  7  0.0000 -0.0000
 9  8 -0.0000  0.0000
 Test Passed
./fft_test_r2c_dp.out
  Transform from real array
 1  0 -0.0000  0.0000
 2  1 -0.0000  0.0000
 3  2  0.5000 -0.0000
 4  3 -0.0000 -0.5000
 5  4  0.0000 -0.0000
 6  5  0.0000 -0.0000
 7  6  0.0000 -0.0000
 8  7  0.0000  0.0000
 9  8 -0.0000  0.0000
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_r2c'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_r2c'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_test_r2c'
cd chapter7/fft_derivative; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_derivative'
nvfortran -Mpreprocess -O2 -cudalib=cufft  -c ../common/precision_m.F90
nvfortran -Mpreprocess -O2 -cudalib=cufft  -c ../common/cufft_m.cuf
nvfortran -Mpreprocess -O2 -cudalib=cufft  -o fft_derivative_sp.out precision_m.o cufft_m.o fft_derivative.cuf 
fft_derivative.cuf:
nvfortran -Mpreprocess -O2 -cudalib=cufft  -DDOUBLE -c ../common/precision_m.F90
nvfortran -Mpreprocess -O2 -cudalib=cufft  -DDOUBLE -c ../common/cufft_m.cuf
nvfortran -Mpreprocess -O2 -cudalib=cufft  -DDOUBLE -o fft_derivative_dp.out precision_m.o cufft_m.o fft_derivative.cuf 
fft_derivative.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_derivative'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_derivative'
./fft_derivative_sp.out
  First Derivative from complex array
 1   3.0000   3.0000  -.2384186E-06
 2  -4.1213  -4.1213  0.0000000E+00
 3  -0.0000   0.0000  -.2381143E-06
 4   4.1213   4.1213  0.0000000E+00
 5  -3.0000  -3.0000  0.0000000E+00
 6   0.1213   0.1213  -.5960464E-07
 7   0.0000  -0.0000  0.4447463E-06
 8  -0.1213  -0.1213  -.2086163E-05
 Test Passed
./fft_derivative_dp.out
  First Derivative from complex array
 1   3.0000   3.0000  0.1332268E-14
 2  -4.1213  -4.1213  -.8881784E-15
 3  -0.0000  -0.0000  -.8927925E-16
 4   4.1213   4.1213  0.8881784E-15
 5  -3.0000  -3.0000  -.8881784E-15
 6   0.1213   0.1213  0.3108624E-14
 7   0.0000   0.0000  -.5882969E-15
 8  -0.1213  -0.1213  -.1665335E-14
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_derivative'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_derivative'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/fft_derivative'
cd chapter7/exampleOverlapFFT; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/exampleOverlapFFT'
nvfortran -O2 -cudalib=cufft  -c ../common/precision_m.F90
nvfortran -O2 -cudalib=cufft  -c ../common/cufft_m.cuf
nvfortran -O2 -cudalib=cufft  -o exampleOverlapFFT.out precision_m.o cufft_m.o exampleOverlapFFT.cuf 
exampleOverlapFFT.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/exampleOverlapFFT'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/exampleOverlapFFT'
./exampleOverlapFFT.out
 I/O only
 Elapsed time :   0.1125030    

Single stream  loop
 Elapsed time :   0.1243220    

Do loop with multiple streams
 Elapsed time :   9.0708002E-02
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/exampleOverlapFFT'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/exampleOverlapFFT'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/chapter7/exampleOverlapFFT'
cd appendixC/sgemmDevice; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/sgemmDevice'
nvfortran -O2 -cudalib=cublas  -o sgemmDevice.out sgemmDevice.cuf
nvfortran -O2 -cudalib=cublas  -o sgemmDeviceOld.out sgemmDeviceOld.cuf
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/sgemmDevice'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/sgemmDevice'
./sgemmDevice.out
 Max error =    0.000000    
 Test Passed
./sgemmDeviceOld.out
 Max error =    0.000000    
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/sgemmDevice'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/sgemmDevice'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/sgemmDevice'
cd appendixC/fCallingC; make build; make run; make clean
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/fCallingC'
nvcc -O3  --generate-code arch=compute_70,code=sm_70 -c zero.cu
nvfortran -O2  -gpu=nordc -o fCallingC.out zero.o fCallingC.cuf
fCallingC.cuf:
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/fCallingC'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/fCallingC'
./fCallingC.out
    0.000000        0.000000        0.000000        0.000000    
 Test Passed
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/fCallingC'
make[1]: Entering directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/fCallingC'
Cleaning up...
make[1]: Leaving directory `/lustre/home/user/m/milias/work/projects/open-collection/computer_science/cuda_fortran/CUDA-Fortran-Book/appendixC/fCallingC'
