#!/bin/bash

## jobname
#SBATCH -J mctcBUILD

##  partition (queue)
##SBATCH -p cascade
##SBATCH -p knl
##SBATCH -p flnr-ice
#SBATCH -p slo-ice
##SBATCH -p flnr-sod

##SBATCH --qos=dirac

## max. execution time
##SBATCH -t 21-00:00:00
#SBATCH -t 0-01:00:00

##SBATCH --exclusive

##SBATCH --mem=640GB
#SBATCH --mem=48GB
##SBATCH --mem=16GB

# do not restart in the case of nodefail!
##SBATCH --no-requeue
##SBATCH --no-kill

#SBATCH -N 1 -n 4

## memory NO !!!
##SBATCH --mem-per-cpu=28G

## stdout/stderr output file
#SBATCH -o log_slurm_job.%j.%N.std_out_err

## mail
#SBATCH --mail-user=milias@theor.jinr.ru
#SBATCH --mail-type=ALL

echo -e "\nRunning on host `hostname`"
echo -e "Start time is `date` \n"
 
echo Job user is $SLURM_JOB_USER and his job $SLURM_JOB_NAME has assigned ID $SLURM_JOBID
echo This job was submitted from the computer $SLURM_SUBMIT_HOST
echo and from the home directory:
echo $SLURM_SUBMIT_DIR
echo
echo It is running on the cluster compute node:
echo $SLURM_CLUSTER_NAME
echo and is employing $SLURM_JOB_NUM_NODES node/nodes:
echo $SLURM_JOB_NODELIST
echo
echo -e "Job partition is $SLURM_JOB_PARTITION \n"
echo The job requests $SLURM_CPUS_ON_NODE CPU per task.

#echo "modules at disposal:"
#module avail
#echo

module purge
#module load openmpi/v4.1.1_gcc1120
#module load GVR/v1.0-1  Python/v3.10.13 ELPA/v2020.05.001_intel2018_python365  CMake/v3.29.2  fftw/v3.3.7-5
#module load LAPACK/v3.12.0_gcc1230 fftw openmpi/v5.0.3_gcc1230 CMake/v3.29.2
#module load LAPACK/v3.12.0_gcc1230  gcc/v12.3.0  CMake/v3.29.2 
module add CMake/v3.29.2 intel/oneapi

echo -e "\n adding git module from source /cvmfs/nica.jinr.ru/sw/os/login.sh latest :"
source /cvmfs/nica.jinr.ru/sw/os/login.sh latest
module add git

echo -e "\n\n List of all loaded modules:"
module list

## CPU model, total numer of CPUs, number of allocated CPUs
echo -e "The node's CPU : \c"; cat /proc/cpuinfo | grep 'model name' | uniq
NPROCS=`cat /proc/cpuinfo | grep processor | wc -l`
echo "This node has total $NPROCS CPUs (available for an EXCLUSIVE job)."
#echo "This node has $SLURM_CPUS_ON_NODE CPUs allocated for SLURM calculations."

echo -e "\n\n The total memory at the node (in GB)"
free -t -g
echo -e "\n"

#DFTD4=/lustre/home/user/m/milias/work/software/dft_dispersion_corrections/dft-d4/dftd4
MCTC=/lustre/home/user/m/milias/work/software/dft_dispersion_corrections/dft-d4/mctc/mctc-lib
MCTC_INSTALL=/lustre/home/user/m/milias/work/software/dft_dispersion_corrections/dft-d4/mctc/mctc_installed
echo -e "\n MCTC=$MCTC"
echo -e "\n MCTC_INSTALL=$MCTC_INSTALL"

echo -e "\n ifort -V: \c"; ifort  -V
echo -e "\n icc -V: \c"; icc  -V
echo -e "\n cmake ? \c"; which cmake; cmake --version
echo -e "\n git ? \c"; which git; git --version

# add MCTC library 
#export   LD_LIBRARY_PATH=/lustre/home/user/m/milias/work/software/dft_dispersion_corrections/dft-d4/mctc/mctc-lib/build_inteloneapi:$LD_LIBRARY_PATH
#export INCLUDE=/lustre/home/user/m/milias/work/software/dft_dispersion_corrections/dft-d4/mctc/mctc-lib/build_inteloneapi/include:$INCLUDE
#export PATH=/lustre/home/user/m/milias/work/software/dft_dispersion_corrections/dft-d4/mctc/mctc-lib/build_inteloneapi:$PATH

echo -e "\nMy PATH=$PATH\n"
echo -e "\n My LD_LIBRARY_PATH=$LD_LIBRARY_PATH "

cd $MCTC
echo -e "\n\n I am in the directory MCTC=$MCTC"; pwd
echo -e "Content of current directory, ls -l : "; ls -l

BUILD=build_inteloneapi
if [ -d $BUILD  ]; then
  echo "Directory BUILD=$BUILD exists. Going to delete it first !"
  /bin/rm -rf $BUILD
  echo "Old directory BUILD=$BUILD deleted."
else
  echo "Directory BUILD=$BUILD does not exists. It will be created"
fi


mkdir $BUILD
cd $BUILD

echo -e "\n\n\n Im in directory MCTC/BUILD=$MCTC/$BUILD"; pwd

echo -e "\n\n running cmake : \n "
FC=ifort CC=icc cmake -DCMAKE_INSTALL_PREFIX=$MCTC_INSTALL ..

echo -e "\n Going to run make .."
#make VERBOSE=1 -j $SLURM_CPUS_ON_NODE
make -j $SLURM_CPUS_ON_NODE


echo -e "\n\n Going to run make install : "
make install

echo -e "\n\n Check $MCTC_INSTALL :"; ls -l $MCTC_INSTALL

echo -e "\n\n Now running ctest -j$SLURM_CPUS_ON_NODE : \n"
ctest -j$SLURM_CPUS_ON_NODE

echo -e "\n\n Finished, time is `date` \n"

exit
