
Job user is SLURM_JOB_USER=mirilias
Job partition is: 
User's job is SLURM_JOB_NAME=QuartzV has assigned ID SLURM_JOBID=11169618
This job was submitted from the computer SLURM_SUBMIT_HOST=login22.mogon
and from the home directory: SLURM_SUBMIT_DIR=/gpfs/fs1/home/mirilias/work/projects/open-collection/theoretical_chemistry/software_runs/quantum-espresso/servers/mogon2.uni-mainz.de/gpu-version/test_run/quartz_slab/oncvpsp
It is running on the cluster compute node: SLURM_CLUSTER_NAME=mogon2
Job  is employing SLURM_JOB_NUM_NODES=1 node/nodes:
SLURM_JOB_NODELIST=s0017
The job requests SLURM_CPUS_ON_NODE=2 CPU per task.

The following have been reloaded with a version change:
  1) compiler/GCCcore/11.2.0 => compiler/GCCcore/8.3.0

List of loaded modules:

Currently Loaded Modules:
  1) devel/CMake/3.21.1
  2) compiler/intel-compilers/2022.0.2
  3) lib/UCX/1.11.2-GCCcore-11.2.0
  4) mpi/impi/2021.5.1-intel-compilers-2022.0.2
  5) system/CUDA/11.4.2
  6) compiler/GCCcore/8.3.0
  7) compiler/PGI/20.4-GCC-8.3.0
  8) system/CUDAcore/11.2.2
  9) compiler/NVHPC/21.7
 10) numlib/imkl/2022.0.2

Running on host s0017.mogon
Time is Mon Jul 11 09:30:25 CEST 2022 


My PATH=/cluster/easybuild/broadwell/software/NVHPC/21.7:/cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/bin:/cluster/easybuild/broadwell/software/CUDAcore/11.2.2:/cluster/easybuild/broadwell/software/CUDAcore/11.2.2/nvvm/bin:/cluster/easybuild/broadwell/software/CUDAcore/11.2.2/bin:/cluster/easybuild/broadwell/software/PGI/20.4-GCC-8.3.0:/cluster/easybuild/broadwell/software/PGI/20.4-GCC-8.3.0/linux86-64/20.4/bin:/cluster/easybuild/broadwell/software/compiler/GCCcore/8.3.0/bin:/cluster/easybuild/broadwell/software/CUDA/11.4.2/nvvm/bin:/cluster/easybuild/broadwell/software/CUDA/11.4.2/bin:/cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/libfabric/bin:/cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/bin:/cluster/easybuild/broadwell/software/UCX/1.11.2-GCCcore-11.2.0/bin:/cluster/easybuild/broadwell/software/intel-compilers/2022.0.2/compiler/2022.0.2/linux/bin/intel64:/cluster/easybuild/broadwell/software/intel-compilers/2022.0.2/compiler/2022.0.2/linux/bin:/cluster/easybuild/broadwell/software/CMake/3.21.1/bin:/usr/lpp/mmfs/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/var/cfengine/bin:.

My LD_LIBRARY_PATH=/cluster/easybuild/broadwell/software/imkl/2022.0.2/mkl/2022.0.2/lib/intel64:/cluster/easybuild/broadwell/software/imkl/2022.0.2/compiler/2022.0.2/linux/compiler/lib/intel64_lin:/cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib:/cluster/easybuild/broadwell/software/CUDAcore/11.2.2/nvvm/lib64:/cluster/easybuild/broadwell/software/CUDAcore/11.2.2/extras/CUPTI/lib64:/cluster/easybuild/broadwell/software/CUDAcore/11.2.2/lib:/cluster/easybuild/broadwell/software/PGI/20.4-GCC-8.3.0/linux86-64/20.4/lib:/cluster/easybuild/broadwell/software/compiler/GCCcore/8.3.0/lib/gcc/x86_64-pc-linux-gnu/8.3.0:/cluster/easybuild/broadwell/software/compiler/GCCcore/8.3.0/lib64:/cluster/easybuild/broadwell/software/compiler/GCCcore/8.3.0/lib:/cluster/easybuild/broadwell/software/CUDA/11.4.2/nvvm/lib64:/cluster/easybuild/broadwell/software/CUDA/11.4.2/extras/CUPTI/lib64:/cluster/easybuild/broadwell/software/CUDA/11.4.2/lib:/cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/libfabric/lib:/cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/lib/release:/cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/lib:/cluster/easybuild/broadwell/software/UCX/1.11.2-GCCcore-11.2.0/lib:/cluster/easybuild/broadwell/software/intel-compilers/2022.0.2/tbb/2021.5.1/lib/intel64/gcc4.8:/cluster/easybuild/broadwell/software/intel-compilers/2022.0.2/compiler/2022.0.2/linux/compiler/lib/intel64_lin:/cluster/easybuild/broadwell/software/intel-compilers/2022.0.2/compiler/2022.0.2/linux/lib/x64:/cluster/easybuild/broadwell/software/intel-compilers/2022.0.2/compiler/2022.0.2/linux/lib

The node's CPU model name	: Intel(R) Xeon(R) CPU E5-2650 v4 @ 2.20GHz
This node has 48 CPUs available.
(i) This node has SLURM_CPUS_ON_NODE=2 CPUs allocated for SLURM calculations.

 The TOTAL memory at the node (in GB); free -t -g
              total        used        free      shared  buff/cache   available
Mem:            125           2         122           0           0         119
Swap:            48           0          48
Total:          174           2         171


 Dependencies of QE main executable, ldd /home/mirilias/work/software/quantum_espresso/qe-7.1/build_impi_gpu/bin/pw.x:
	linux-vdso.so.1 (0x00007fd0931a7000)
	libmpifort.so.12 => /cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/lib/libmpifort.so.12 (0x00007fd092bc9000)
	libmpi.so.12 => /cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/lib/release/libmpi.so.12 (0x00007fd091394000)
	librt.so.1 => /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/librt.so.1 (0x00007fd09118c000)
	libpthread.so.0 => /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/libpthread.so.0 (0x00007fd090f6c000)
	libdl.so.2 => /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/libdl.so.2 (0x00007fd090d68000)
	libacchost.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libacchost.so (0x00007fd090af8000)
	libmkl_intel_lp64.so.2 => /cluster/easybuild/broadwell/software/imkl/2022.0.2/mkl/2022.0.2/lib/intel64/libmkl_intel_lp64.so.2 (0x00007fd08fc58000)
	libmkl_intel_thread.so.2 => /cluster/easybuild/broadwell/software/imkl/2022.0.2/mkl/2022.0.2/lib/intel64/libmkl_intel_thread.so.2 (0x00007fd08c4f6000)
	libmkl_core.so.2 => /cluster/easybuild/broadwell/software/imkl/2022.0.2/mkl/2022.0.2/lib/intel64/libmkl_core.so.2 (0x00007fd088141000)
	libiomp5.so => /cluster/easybuild/broadwell/software/imkl/2022.0.2/compiler/2022.0.2/linux/compiler/lib/intel64_lin/libiomp5.so (0x00007fd087d20000)
	libm.so.6 => /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/libm.so.6 (0x00007fd08799e000)
	libcufft.so.10 => /cluster/easybuild/broadwell/software/CUDAcore/11.2.2/lib64/libcufft.so.10 (0x00007fd07c1ef000)
	libcudaforwraprand.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libcudaforwraprand.so (0x00007fd07bfec000)
	libcurand.so.10 => /cluster/easybuild/broadwell/software/CUDAcore/11.2.2/lib64/libcurand.so.10 (0x00007fd076885000)
	libcusolver.so.11 => /cluster/easybuild/broadwell/software/CUDAcore/11.2.2/lib64/libcusolver.so.11 (0x00007fd05e7cf000)
	libcublas.so.11 => /cluster/easybuild/broadwell/software/CUDAcore/11.2.2/lib64/libcublas.so.11 (0x00007fd05780c000)
	libcublasLt.so.11 => /cluster/easybuild/broadwell/software/CUDAcore/11.2.2/lib64/libcublasLt.so.11 (0x00007fd04bc2b000)
	libcudaforwrapblas.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libcudaforwrapblas.so (0x00007fd04b9ee000)
	libcudart.so.11.0 => /cluster/easybuild/broadwell/software/CUDAcore/11.2.2/lib64/libcudart.so.11.0 (0x00007fd04b75f000)
	libcudafor_110.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libcudafor_110.so (0x00007fd047bac000)
	libcudafor.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libcudafor.so (0x00007fd04798f000)
	libaccdevaux.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libaccdevaux.so (0x00007fd047783000)
	libacccuda.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libacccuda.so (0x00007fd047451000)
	libcudadevice.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libcudadevice.so (0x00007fd04723e000)
	libcudafor2.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libcudafor2.so (0x00007fd04703b000)
	libnvf.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libnvf.so (0x00007fd046a11000)
	libnvomp.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libnvomp.so (0x00007fd045d97000)
	libnvcpumath.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libnvcpumath.so (0x00007fd045962000)
	libnvc.so => /cluster/easybuild/broadwell/software/NVHPC/21.7/Linux_x86_64/21.7/compilers/lib/libnvc.so (0x00007fd04570a000)
	libc.so.6 => /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/libc.so.6 (0x00007fd045345000)
	libgcc_s.so.1 => /usr/lib/gcc/x86_64-redhat-linux/8/../../../../lib64/libgcc_s.so.1 (0x00007fd04512d000)
	/lib64/ld-linux-x86-64.so.2 (0x00007fd092f7d000)
	libstdc++.so.6 => /cluster/easybuild/broadwell/software/compiler/GCCcore/8.3.0/lib64/libstdc++.so.6 (0x00007fd093004000)

Python -v :Python 2.7.18
mpirun ? which mpirun  = /cluster/easybuild/broadwell/software/impi/2021.5.1-intel-compilers-2022.0.2/mpi/2021.5.1/bin/mpirun
mpirun --version Intel(R) MPI Library for Linux* OS, Version 2021.5 Build 20211102 (id: 9279b7d62)
Copyright 2003-2021, Intel Corporation.

 Current directory where this SLURM job is running /gpfs/fs1/home/mirilias/work/projects/open-collection/theoretical_chemistry/software_runs/quantum-espresso/servers/mogon2.uni-mainz.de/gpu-version/test_run/quartz_slab/oncvpsp
 It has the disk space of (df -h) :
Filesystem                 Size  Used Avail Use% Mounted on
10.80.0.47:/gpfs/fs1/home  120T   41T   79T  35% /gpfs/fs1/home

Out of memory allocating 34557774336 bytes of device memory
Failing in Thread:1
total/free CUDA memory: 11721572352/10875240448
Present table dump for device[1]: NVIDIA Tesla GPU 0, compute capability 6.1, threadid=1
host:0x496cf40 device:0x7f7872405000 size:1752 presentcount:0+1 line:-1 name:_xdm_module_21
host:0x49b1c80 device:0x7f7872404500 size:184 presentcount:0+1 line:-1 name:_cell_base_21
host:0x4bdf500 device:0x7f7872405a00 size:160 presentcount:0+1 line:-1 name:_vdw_df_21
host:0x4bdf900 device:0x7f7872405b00 size:160 presentcount:0+1 line:-1 name:_rvv10_21
host:0x4da7020 device:0x7f7872406300 size:240 presentcount:0+1 line:-1 name:_st__home_mirilias_work_software_quantum_espresso_qe_7_1_XClib_beefun_c_mi
host:0x4da8f18 device:0x7f7872406400 size:4 presentcount:0+1 line:-1 name:_st__home_mirilias_work_software_quantum_espresso_qe_7_1_XClib_beefun_c_beeforder
host:0x4e19554 device:0x7f7872406500 size:4 presentcount:0+1 line:-1 name:_st__home_mirilias_work_software_quantum_espresso_qe_7_1_XClib_beefun_c_beeftype
host:0x4e26580 device:0x7f7872404e00 size:432 presentcount:0+1 line:-1 name:_exx_16
host:0x519d3c0 device:0x7f7872402500 size:336 presentcount:0+1 line:-1 name:_klist_16
host:0x519d590 device:0x7f7873ffea00 size:176 presentcount:0+1 line:93 name:descriptor
host:0x51ac140 device:0x7f7872404900 size:528 presentcount:0+1 line:-1 name:_wvfct_gpum_16
host:0x51ac3c0 device:0x7f7872405700 size:192 presentcount:0+1 line:-1 name:_scf_gpum_16
host:0x51ad940 device:0x7f7872404c00 size:192 presentcount:0+1 line:-1 name:_exx_band_16
host:0x51adec0 device:0x7f7872404300 size:384 presentcount:0+1 line:-1 name:_g_psi_mod_gpum_16
host:0x51afb80 device:0x7f7872405900 size:144 presentcount:0+1 line:-1 name:_electrons_base_16
host:0x51afd80 device:0x7f7872405800 size:144 presentcount:0+1 line:-1 name:_gvecw_16
host:0x51b0f00 device:0x7f7872404d00 size:144 presentcount:0+1 line:-1 name:_mp_exx_16
host:0x51b23c0 device:0x7f7872402700 size:1392 presentcount:0+1 line:-1 name:_gvect_16
host:0x51b2b00 device:0x7f7873e5be00 size:176 presentcount:0+1 line:123 name:descriptor
host:0x51b2bc0 device:0x7f7873e5bc00 size:176 presentcount:0+1 line:123 name:descriptor
host:0x51b2dd0 device:0x7f7873ff6e00 size:176 presentcount:0+1 line:43 name:descriptor
host:0x51b2e90 device:0x7f7873ff7000 size:176 presentcount:0+1 line:43 name:descriptor
host:0x51b2f50 device:0x7f7873ff7200 size:176 presentcount:0+1 line:43 name:descriptor
host:0x51b5f40 device:0x7f7872404000 size:576 presentcount:0+1 line:-1 name:_wavefunctions_16
host:0x5ebb300 device:0x7f7872404600 size:528 presentcount:0+1 line:-1 name:_wavefunctions_gpum_16
host:0x5ec0640 device:0x7f7872402d00 size:336 presentcount:0+1 line:-1 name:_upf_spinorb_16
host:0x5f23980 device:0x7f7872402f00 size:4176 presentcount:0+1 line:-1 name:_uspp_16
host:0x5f30f00 device:0x7f7872405c00 size:768 presentcount:0+1 line:-1 name:_uspp_data_16
host:0x606e500 device:0x7f7872405f00 size:288 presentcount:0+1 line:-1 name:_fft_buffers_16
host:0x6071500 device:0x7f7872406100 size:288 presentcount:0+1 line:-1 name:_data_buffer_16
host:0xdab7320 device:0x7f7819e00000 size:2053120 presentcount:0+1 line:43 name:eigts1
host:0x13117390 device:0x7f7877a00000 size:2309120 presentcount:0+1 line:43 name:eigts2
host:0x1334efb0 device:0x7f77f8000000 size:3691520 presentcount:0+1 line:43 name:eigts3
host:0x7f77f8400000 device:0x7f77f8c00000 size:7882704 presentcount:0+1 line:93 name:igk_k
host:0x7f785ebe6650 device:0x7f7850000000 size:47289372 presentcount:0+1 line:123 name:mill
host:0x7f7861900440 device:0x7f784a000000 size:94578744 presentcount:0+1 line:123 name:g
allocated block device:0x7f77f8000000 size:3691520 thread:1
allocated block device:0x7f77f8c00000 size:7882752 thread:1
allocated block device:0x7f7819e00000 size:2053120 thread:1
allocated block device:0x7f784a000000 size:94579200 thread:1
allocated block device:0x7f7850000000 size:47289856 thread:1
allocated block device:0x7f7873e5bc00 size:512 thread:1
allocated block device:0x7f7873e5be00 size:512 thread:1
allocated block device:0x7f7873ff6e00 size:512 thread:1
allocated block device:0x7f7873ff7000 size:512 thread:1
allocated block device:0x7f7873ff7200 size:512 thread:1
allocated block device:0x7f7873ffea00 size:512 thread:1
allocated block device:0x7f7877a00000 size:2309120 thread:1
call to cuMemAlloc returned error 2: Out of memory

Out of memory allocating 34555599872 bytes of device memory
Failing in Thread:1
total/free CUDA memory: 11721572352/10875240448
Present table dump for device[2]: NVIDIA Tesla GPU 1, compute capability 6.1, threadid=1
host:0x496cf40 device:0x7fd284405000 size:1752 presentcount:0+1 line:-1 name:_xdm_module_21
host:0x49b1c80 device:0x7fd284404500 size:184 presentcount:0+1 line:-1 name:_cell_base_21
host:0x4bdf500 device:0x7fd284405a00 size:160 presentcount:0+1 line:-1 name:_vdw_df_21
host:0x4bdf900 device:0x7fd284405b00 size:160 presentcount:0+1 line:-1 name:_rvv10_21
host:0x4da7020 device:0x7fd284406300 size:240 presentcount:0+1 line:-1 name:_st__home_mirilias_work_software_quantum_espresso_qe_7_1_XClib_beefun_c_mi
host:0x4da8f18 device:0x7fd284406400 size:4 presentcount:0+1 line:-1 name:_st__home_mirilias_work_software_quantum_espresso_qe_7_1_XClib_beefun_c_beeforder
host:0x4e19554 device:0x7fd284406500 size:4 presentcount:0+1 line:-1 name:_st__home_mirilias_work_software_quantum_espresso_qe_7_1_XClib_beefun_c_beeftype
host:0x4e26580 device:0x7fd284404e00 size:432 presentcount:0+1 line:-1 name:_exx_16
host:0x519d3c0 device:0x7fd284402500 size:336 presentcount:0+1 line:-1 name:_klist_16
host:0x519d590 device:0x7fd285ffea00 size:176 presentcount:0+1 line:93 name:descriptor
host:0x51ac140 device:0x7fd284404900 size:528 presentcount:0+1 line:-1 name:_wvfct_gpum_16
host:0x51ac3c0 device:0x7fd284405700 size:192 presentcount:0+1 line:-1 name:_scf_gpum_16
host:0x51ad940 device:0x7fd284404c00 size:192 presentcount:0+1 line:-1 name:_exx_band_16
host:0x51adec0 device:0x7fd284404300 size:384 presentcount:0+1 line:-1 name:_g_psi_mod_gpum_16
host:0x51afb80 device:0x7fd284405900 size:144 presentcount:0+1 line:-1 name:_electrons_base_16
host:0x51afd80 device:0x7fd284405800 size:144 presentcount:0+1 line:-1 name:_gvecw_16
host:0x51b0f00 device:0x7fd284404d00 size:144 presentcount:0+1 line:-1 name:_mp_exx_16
host:0x51b23c0 device:0x7fd284402700 size:1392 presentcount:0+1 line:-1 name:_gvect_16
host:0x51b2b00 device:0x7fd285e5be00 size:176 presentcount:0+1 line:123 name:descriptor
host:0x51b2bc0 device:0x7fd285e5bc00 size:176 presentcount:0+1 line:123 name:descriptor
host:0x51b2dd0 device:0x7fd285ff6e00 size:176 presentcount:0+1 line:43 name:descriptor
host:0x51b2e90 device:0x7fd285ff7000 size:176 presentcount:0+1 line:43 name:descriptor
host:0x51b2f50 device:0x7fd285ff7200 size:176 presentcount:0+1 line:43 name:descriptor
host:0x51b5f40 device:0x7fd284404000 size:576 presentcount:0+1 line:-1 name:_wavefunctions_16
host:0x5ebb300 device:0x7fd284404600 size:528 presentcount:0+1 line:-1 name:_wavefunctions_gpum_16
host:0x5ec0640 device:0x7fd284402d00 size:336 presentcount:0+1 line:-1 name:_upf_spinorb_16
host:0x5f23980 device:0x7fd284402f00 size:4176 presentcount:0+1 line:-1 name:_uspp_16
host:0x5f30f00 device:0x7fd284405c00 size:768 presentcount:0+1 line:-1 name:_uspp_data_16
host:0x606e500 device:0x7fd284405f00 size:288 presentcount:0+1 line:-1 name:_fft_buffers_16
host:0x6071500 device:0x7fd284406100 size:288 presentcount:0+1 line:-1 name:_data_buffer_16
host:0x121e53b0 device:0x7fd22de00000 size:2053120 presentcount:0+1 line:43 name:eigts1
host:0x123de5c0 device:0x7fd2a3a00000 size:2309120 presentcount:0+1 line:43 name:eigts2
host:0x126161e0 device:0x7fd20c000000 size:3691520 presentcount:0+1 line:43 name:eigts3
host:0x7fd20c400000 device:0x7fd20cc00000 size:7882208 presentcount:0+1 line:93 name:igk_k
host:0x7fd2729f7650 device:0x7fd264000000 size:47289360 presentcount:0+1 line:123 name:mill
host:0x7fd275711440 device:0x7fd25e000000 size:94578720 presentcount:0+1 line:123 name:g
allocated block device:0x7fd20c000000 size:3691520 thread:1
allocated block device:0x7fd20cc00000 size:7882240 thread:1
allocated block device:0x7fd22de00000 size:2053120 thread:1
allocated block device:0x7fd25e000000 size:94579200 thread:1
allocated block device:0x7fd264000000 size:47289856 thread:1
allocated block device:0x7fd285e5bc00 size:512 thread:1
allocated block device:0x7fd285e5be00 size:512 thread:1
allocated block device:0x7fd285ff6e00 size:512 thread:1
allocated block device:0x7fd285ff7000 size:512 thread:1
allocated block device:0x7fd285ff7200 size:512 thread:1
allocated block device:0x7fd285ffea00 size:512 thread:1
allocated block device:0x7fd2a3a00000 size:2309120 thread:1
call to cuMemAlloc returned error 2: Out of memory

