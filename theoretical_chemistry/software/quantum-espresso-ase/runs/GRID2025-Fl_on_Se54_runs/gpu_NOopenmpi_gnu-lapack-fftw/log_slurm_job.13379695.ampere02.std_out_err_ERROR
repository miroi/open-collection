
Running on host ampere02.hydra.local
Time is Fri Aug 29 07:53:05 MSK 2025 


Job user is SLURM_JOB_USER= milias
User job SLURM_JOB_NAME=FlSe54qe2 has assigned ID SLURM_JOBID=13379695
This job was submitted from the computer SLURM_SUBMIT_HOST=space02.hydra.local
and from the home directory SLURM_SUBMIT_DIR:
/lustre/home/user/m/milias/work/projects/open-collection/theoretical_chemistry/software/quantum-espresso-ase/runs/GRID2025-Fl_on_Se54_runs/gpu_NOopenmpi_gnu-lapack-fftw
Job is running on the cluster compute node: SLURM_CLUSTER_NAME=gvr
and is employing SLURM_JOB_NUM_NODES=1 node/nodes:
SLURM_JOB_NODELIST = ampere02
Job partition is SLURM_JOB_PARTITION=ampere 

Number of allocated CPUs on each single node, SLURM_CPUS_ON_NODE=12 .
Number of all reserved threads over ALL nodes, SLURM_NTASKS=12 .
Job has reserved memory per node, SLURM_MEM_PER_NODE=307200 MB of memory
srun: error: fwd_tree_thread: can't find address for host ampere02, check slurm.conf
srun: error: Task launch for 13379695.0 failed on node ampere02: Can't find an address, check slurm.conf
srun: error: Application launch failed: Can't find an address, check slurm.conf
srun: Job step aborted: Waiting up to 122 seconds for job step to finish.
srun: error: Timed out waiting for job step to complete

generated machinefile for MPI, nodes.ampere.13379695
-rw-r--r--. 1 milias hybrilit 0 Aug 29 07:53 /lustre/home/user/m/milias/work/projects/open-collection/theoretical_chemistry/software/quantum-espresso-ase/runs/GRID2025-Fl_on_Se54_runs/gpu_NOopenmpi_gnu-lapack-fftw/nodes.ampere.13379695
containing:
The node's CPU model name	: AMD EPYC 7763 64-Core Processor
BTW, this node has total 256 CPUs available for an EXCLUSIVE job.
Based on reserved memory, this node got 12 CPUs allocated for SLURM calculations.
This job wants SLURM_NTASKS=12 threads . 


 loaded modules:
Currently Loaded Modulefiles:
  1) GVR/v1.0-1                6) LAPACK/v3.12.0_gcc1230
  2) BASE/1.0                  7) openmpi/v5.0.3_gcc1230
  3) Python/v3.10.13           8) fftw/v3.3.10_openmpi503
  4) CMake/v3.29.2             9) cuda/v12.4
  5) gcc/v12.3.0

Running on host ampere02.hydra.local
Time is Fri Aug 29 07:55:08 MSK 2025 


 The total memory at the node (in GB)
              total        used        free      shared  buff/cache   available
Mem:           2003          59        1943           0           0        1941
Swap:            31           0          31
Total:         2035          59        1975



 ldd  /lustre/home/user/m/milias/work/software/quantum-espresso/qe-develop/q-e/build_gpu_cuda_NOopenmpi_lapack/bin/pw.x :
	linux-vdso.so.1 =>  (0x00007ffdad3e3000)
	libfftw3.so.3 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/fftw/v3.3.10_openmpi503/lib/libfftw3.so.3 (0x00002ab181b0d000)
	libfftw3_omp.so.3 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/fftw/v3.3.10_openmpi503/lib/libfftw3_omp.so.3 (0x00002ab181f35000)
	liblapack.so.3 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/LAPACK/v3.12.0_gcc1230/lib64/liblapack.so.3 (0x00002ab18213c000)
	libblas.so.3 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/LAPACK/v3.12.0_gcc1230/lib64/libblas.so.3 (0x00002ab182a20000)
	libnvhpcwrapcufft.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libnvhpcwrapcufft.so (0x00002ab182cc3000)
	libcufft.so.11 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/math_libs/12.4/lib64/libcufft.so.11 (0x00002ab182ec5000)
	libcudaforwraprand.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libcudaforwraprand.so (0x00002ab194ac2000)
	libcurand.so.10 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/math_libs/12.4/lib64/libcurand.so.10 (0x00002ab194cc5000)
	libcusolver.so.11 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/math_libs/12.4/lib64/libcusolver.so.11 (0x00002ab19b10b000)
	libnvJitLink.so.12 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/cuda/12.4/lib64/libnvJitLink.so.12 (0x00002ab1a25a5000)
	libcublas.so.12 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/math_libs/12.4/lib64/libcublas.so.12 (0x00002ab1a5b38000)
	libcublasLt.so.12 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/math_libs/12.4/lib64/libcublasLt.so.12 (0x00002ab1ac5f0000)
	libcudaforwrapblas.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libcudaforwrapblas.so (0x00002ab1ca487000)
	libcudaforwrapblas117.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libcudaforwrapblas117.so (0x00002ab1ca6c8000)
	libcudart.so.12 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/cuda/12.4/lib64/libcudart.so.12 (0x00002ab1ca8d9000)
	libcudafor_120.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libcudafor_120.so (0x00002ab1cab88000)
	libcudafor.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libcudafor.so (0x00002ab1d138a000)
	libacchost.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libacchost.so (0x00002ab1d159f000)
	libaccdevaux.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libaccdevaux.so (0x00002ab1d1804000)
	libacccuda.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libacccuda.so (0x00002ab1d1a21000)
	libdl.so.2 => /lib64/libdl.so.2 (0x00002ab1d1d52000)
	libcudadevice.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libcudadevice.so (0x00002ab1d1f56000)
	libcudafor2.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libcudafor2.so (0x00002ab1d216d000)
	libnvf.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libnvf.so (0x00002ab1d2370000)
	libnvomp.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libnvomp.so (0x00002ab1d2a90000)
	libpthread.so.0 => /lib64/libpthread.so.0 (0x00002ab1d3a91000)
	libnvcpumath.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libnvcpumath.so (0x00002ab1d3cad000)
	libnvc.so => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/lib/libnvc.so (0x00002ab1d411a000)
	librt.so.1 => /lib64/librt.so.1 (0x00002ab1d437e000)
	libc.so.6 => /lib64/libc.so.6 (0x00002ab1d4586000)
	libgcc_s.so.1 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/gcc/v12.3.0/lib64/libgcc_s.so.1 (0x00002ab1d4954000)
	libm.so.6 => /lib64/libm.so.6 (0x00002ab1d4b72000)
	libgfortran.so.5 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/gcc/v12.3.0/lib64/libgfortran.so.5 (0x00002ab1d4e74000)
	libquadmath.so.0 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/gcc/v12.3.0/lib64/libquadmath.so.0 (0x00002ab1d533a000)
	/lib64/ld-linux-x86-64.so.2 (0x00002ab1818e9000)
	libcusparse.so.12 => /cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/lib64/libcusparse.so.12 (0x00002ab1d557f000)


 My PATH=/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/comm_libs/mpi/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/Linux_x86_64/24.5/compilers/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/fftw/v3.3.10_openmpi503/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/openmpi/v5.0.3_gcc1230/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/gcc/v12.3.0/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/CMake/v3.29.2/bin:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/Python/v3.10.13/bin:/lustre/home/user/m/milias/work/software/ams/linux.openmpi/ams2021.107/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:.:/lustre/home/user/m/milias/.local/bin:/lustre/home/user/m/milias/bin


My LD_LIBRARY_PATH=/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/cuda/v12.4/lib64:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/fftw/v3.3.10_openmpi503/lib:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/openmpi/v5.0.3_gcc1230/lib:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/LAPACK/v3.12.0_gcc1230/lib64:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/LAPACK/v3.12.0_gcc1230/lib:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/gcc/v12.3.0/lib64:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/Python/v3.10.13/lib64:/cvmfs/hybrilit.jinr.ru/sw/slc7_x86-64/Python/v3.10.13/lib 
Python -v :Python 3.10.13

 Current directory where this SLURM job is running /lustre/home/user/m/milias/work/projects/open-collection/theoretical_chemistry/software/quantum-espresso-ase/runs/GRID2025-Fl_on_Se54_runs/gpu_NOopenmpi_gnu-lapack-fftw
 It has the disk space of (df -h) :
Filesystem                  Size  Used Avail Use% Mounted on
10.220.24.208:/lustre/home  650T  549T  102T  85% /lustre/home



 OMP_NUM_THREADS=12
Warning: ieee_inexact is signaling
    1


 QE finished on : Fri Aug 29 17:01:11 MSK 2025
